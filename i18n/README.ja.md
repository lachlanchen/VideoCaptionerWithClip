[English](../README.md) Â· [Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©](README.ar.md) Â· [EspaÃ±ol](README.es.md) Â· [FranÃ§ais](README.fr.md) Â· [æ—¥æœ¬èª](README.ja.md) Â· [í•œêµ­ì–´](README.ko.md) Â· [Tiáº¿ng Viá»‡t](README.vi.md) Â· [ä¸­æ–‡ (ç®€ä½“)](README.zh-Hans.md) Â· [ä¸­æ–‡ï¼ˆç¹é«”ï¼‰](README.zh-Hant.md) Â· [Deutsch](README.de.md) Â· [Ğ ÑƒÑÑĞºĞ¸Ğ¹](README.ru.md)



[![LazyingArt banner](https://github.com/lachlanchen/lachlanchen/raw/main/figs/banner.png)](https://github.com/lachlanchen/lachlanchen/blob/main/figs/banner.png)


# Clip-GPT-Captioning

![Python](https://img.shields.io/badge/Python-3.10%2B-blue)
![PyTorch](https://img.shields.io/badge/PyTorch-2.x-red)
![Transformers](https://img.shields.io/badge/HuggingFace-Transformers-yellow)
![Status](https://img.shields.io/badge/README-Expanded-success)
![Repo Layout](https://img.shields.io/badge/Layout-Root%20Scripts-informational)
![Legacy Scripts](https://img.shields.io/badge/Legacy%20Scripts-Present-orange)
![i18n](https://img.shields.io/badge/i18n-Enabled-brightgreen)
![Maintained Path](https://img.shields.io/badge/Video-v2c.py-2ea44f)
![Contributions](https://img.shields.io/badge/Contributions-Welcome-2ea44f?style=flat-square)
![Issues](https://img.shields.io/github/issues-raw/lachlanchen/VideoCaptionerWithClip?style=flat-square)
![Last Commit](https://img.shields.io/github/last-commit/lachlanchen/VideoCaptionerWithClip?style=flat-square)

---

## ğŸ§­ Quick Navigation

| ã‚»ã‚¯ã‚·ãƒ§ãƒ³ | ç”¨é€” |
|---|---|
| Snapshot | ãƒªãƒã‚¸ãƒˆãƒªã®ç¯„å›²ã¨ç¾è¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆæ§‹æˆã‚’æŠŠæ¡ |
| Overview | ç›®çš„ã¨æ©Ÿèƒ½ã‚’ç¢ºèª |
| Usage | CLI/API ã®æ“ä½œæ‰‹é †ã‚’ç¢ºèª |
| Troubleshooting | ã‚ˆãã‚ã‚‹å®Ÿè¡Œã‚¨ãƒ©ãƒ¼ã‚’è¿…é€Ÿã«è§£æ¶ˆ |
| Roadmap | æ•´ç†ãƒ»æ”¹å–„ã®å¯¾è±¡ã‚’æŠŠæ¡ |

---

OpenAI ã® CLIP è¦–è¦šåŸ‹ã‚è¾¼ã¿ã¨ GPT ç³»è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’çµ„ã¿åˆã‚ã›ã€ç”»åƒã¨å‹•ç”»ã®è‡ªç„¶è¨€èªã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆã™ã‚‹ Python ãƒ„ãƒ¼ãƒ«ã‚­ãƒƒãƒˆã§ã™ã€‚

## ğŸ§­ Snapshot

| é …ç›® | å†…å®¹ |
|---|---|
| å¯¾å¿œã‚¿ã‚¹ã‚¯ | ç”»åƒã¨å‹•ç”»ã®ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ç”Ÿæˆ |
| ä¸»ãªå‡ºåŠ› | SRT å­—å¹•ã€JSON ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆã€ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ä»˜ãç”»åƒ |
| ä¸»è¦ã‚¹ã‚¯ãƒªãƒ—ãƒˆ | `i2c.py`ã€`v2c.py`ã€`image2caption.py` |
| ãƒ¬ã‚¬ã‚·ãƒ¼ãƒ‘ã‚¹ | `video2caption.py` ãŠã‚ˆã³æ´¾ç”Ÿç‰ˆï¼ˆå±¥æ­´ä¿æŒã®ãŸã‚ä¿æŒï¼‰ |
| ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æµã‚Œ | `data/raw/results.csv` + `data/raw/flickr30k_images/` |

## âœ¨ Overview

ã“ã®ãƒªãƒã‚¸ãƒˆãƒªã¯ä»¥ä¸‹ã‚’æä¾›ã—ã¾ã™ã€‚

- ç”»åƒã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã¨å‹•ç”»å­—å¹•ç”Ÿæˆã®æ¨è«–ã‚¹ã‚¯ãƒªãƒ—ãƒˆã€‚
- CLIP è¦–è¦šåŸ‹ã‚è¾¼ã¿ã‚’ GPT-2 ãƒˆãƒ¼ã‚¯ãƒ³åŸ‹ã‚è¾¼ã¿ã¸å†™åƒã™ã‚‹å­¦ç¿’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã€‚
- Flickr30k å½¢å¼ãƒ‡ãƒ¼ã‚¿å‘ã‘ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç”Ÿæˆãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã€‚
- é‡ã¿ãŒå­˜åœ¨ã—ãªã„å ´åˆã€å¯¾å¿œã‚µã‚¤ã‚ºã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’è‡ªå‹•ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã€‚
- `i18n/` é…ä¸‹ã®å¤šè¨€èª READMEï¼ˆä¸Šéƒ¨ã®è¨€èªãƒãƒ¼ã‚’å‚ç…§ï¼‰ã€‚

ç¾åœ¨ã®å®Ÿè£…ã§ã¯ã€æ–°è¦ã¨ãƒ¬ã‚¬ã‚·ãƒ¼ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆãŒæ··åœ¨ã—ã¦ã„ã¾ã™ã€‚ã„ãã¤ã‹ã®ãƒ¬ã‚¬ã‚·ãƒ¼ãªãƒ•ã‚¡ã‚¤ãƒ«ã¯å‚ç…§ç”¨ã¨ã—ã¦æ®‹ã£ã¦ãŠã‚Šã€ä»¥ä¸‹ã§è£œè¶³ã—ã¾ã™ã€‚

## ğŸš€ Features

- `image2caption.py` ã«ã‚ˆã‚‹å˜ç”»åƒã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã€‚
- `v2c.py` ã‹ `video2caption.py` ã«ã‚ˆã‚‹å‹•ç”»ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ï¼ˆå‡ä¸€ãƒ•ãƒ¬ãƒ¼ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼‰ã€‚
- å®Ÿè¡Œæ™‚ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºå¯èƒ½:
  - ãƒ•ãƒ¬ãƒ¼ãƒ æ•°
  - ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚º
  - ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ¸©åº¦
  - ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆå
- ãƒãƒ«ãƒãƒ—ãƒ­ã‚»ã‚¹/ã‚¹ãƒ¬ãƒƒãƒ‰å¯¾å¿œã§å‹•ç”»æ¨è«–ã‚’é«˜é€ŸåŒ–ã€‚
- å‡ºåŠ›æˆæœç‰©:
  - SRT å­—å¹•ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ`.srt`ï¼‰
  - `v2c.py` ã® JSON ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆ`.json`ï¼‰
- CLIP + GPT2 ãƒãƒƒãƒ”ãƒ³ã‚°å®Ÿé¨“ç”¨ã®å­¦ç¿’ãƒ»è©•ä¾¡ã‚¨ãƒ³ãƒˆãƒªãƒã‚¤ãƒ³ãƒˆã€‚

### At a glance

| é ˜åŸŸ | ä¸»ãªã‚¹ã‚¯ãƒªãƒ—ãƒˆ | å‚™è€ƒ |
|---|---|---|
| ç”»åƒã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ | `image2caption.py`ã€`i2c.py`ã€`predict.py` | CLI ã¨å†åˆ©ç”¨å¯èƒ½ãªã‚¯ãƒ©ã‚¹ |
| å‹•ç”»ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ | `v2c.py` | æ¨å¥¨ã®ä¿å®ˆå¯¾è±¡ |
| ãƒ¬ã‚¬ã‚·ãƒ¼å‹•ç”»ãƒ•ãƒ­ãƒ¼ | `video2caption.py`ã€`video2caption_v1.1.py` | æ©Ÿæä¾å­˜ã®å‰æã‚’å«ã‚€ |
| ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ§‹ç¯‰ | `dataset_generation.py` | `data/processed/dataset.pkl` ã‚’ç”Ÿæˆ |
| å­¦ç¿’ãƒ»è©•ä¾¡ | `training.py`ã€`evaluate.py` | CLIP + GPT2 ã®å†™åƒã‚’ä½¿ç”¨ |

## ğŸ§± Architecture (High Level)

`model/model.py` ã®ã‚³ã‚¢ãƒ¢ãƒ‡ãƒ«ã¯ 3 ã¤ã®æ§‹æˆè¦ç´ ã‹ã‚‰ãªã‚Šã¾ã™ã€‚

1. `ImageEncoder`: CLIP ç”»åƒåŸ‹ã‚è¾¼ã¿ã‚’æŠ½å‡ºã€‚
2. `Mapping`: CLIP åŸ‹ã‚è¾¼ã¿ã‚’ GPT ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹åŸ‹ã‚è¾¼ã¿åˆ—ã¸æŠ•å½±ã€‚
3. `TextDecoder`: GPT-2 è¨€èªãƒ¢ãƒ‡ãƒ«ãƒ˜ãƒƒãƒ‰ã¨ã—ã¦ã€è‡ªå·±å›å¸°ã§ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ç”Ÿæˆã€‚

å­¦ç¿’ï¼ˆ`Net.train_forward`ï¼‰ã¯ã€äº‹å‰è¨ˆç®—æ¸ˆã¿ã® CLIP ç”»åƒåŸ‹ã‚è¾¼ã¿ã¨ãƒˆãƒ¼ã‚¯ãƒ³åŒ–æ¸ˆã¿ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã‚’ä½¿ã„ã¾ã™ã€‚
æ¨è«–ï¼ˆ`Net.forward`ï¼‰ã¯ PIL ç”»åƒã‚’å—ã‘å–ã‚Šã€EOS ã¾ãŸã¯ `max_len` ã«é”ã™ã‚‹ã¾ã§ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ãƒ‡ã‚³ãƒ¼ãƒ‰ã—ã¾ã™ã€‚

### Data flow

1. ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæº–å‚™: `dataset_generation.py` ãŒ `data/raw/results.csv` ã¨ `data/raw/flickr30k_images/` ã®ç”»åƒã‚’èª­ã¿å–ã‚Šã€`data/processed/dataset.pkl` ã‚’ç”Ÿæˆã—ã¾ã™ã€‚
2. å­¦ç¿’: `training.py` ãŒ pickle åŒ–ã•ã‚ŒãŸã‚¿ãƒ—ãƒ« `(image_name, image_embedding, caption)` ã‚’èª­ã¿è¾¼ã¿ã€ãƒãƒƒãƒ‘ãƒ¼/ãƒ‡ã‚³ãƒ¼ãƒ€å±¤ã‚’å­¦ç¿’ã—ã¾ã™ã€‚
3. è©•ä¾¡: `evaluate.py` ãŒãƒ›ãƒ¼ãƒ«ãƒ‰ã‚¢ã‚¦ãƒˆæ¸ˆã¿ãƒ†ã‚¹ãƒˆç”»åƒã«å¯¾ã—ã¦ç”Ÿæˆã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã‚’ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ã—ã¾ã™ã€‚
4. æ¨è«–å®Ÿè¡Œ:
   - ç”»åƒ: `image2caption.py` / `predict.py` / `i2c.py`
   - å‹•ç”»: `v2c.py`ï¼ˆæ¨å¥¨ï¼‰ã€`video2caption.py`ï¼ˆãƒ¬ã‚¬ã‚·ãƒ¼ï¼‰

## ğŸ—‚ï¸ Project Structure

```text
VideoCaptionerWithClip/
â”œâ”€â”€ README.md
â”œâ”€â”€ image2caption.py               # Single-image caption CLI
â”œâ”€â”€ predict.py                     # Alternate single-image caption CLI
â”œâ”€â”€ i2c.py                         # Reusable ImageCaptioner class + CLI
â”œâ”€â”€ v2c.py                         # Video -> SRT + JSON (threaded frame captioning)
â”œâ”€â”€ video2caption.py               # Alternate video -> SRT implementation (legacy constraints)
â”œâ”€â”€ video2caption_v1.1.py          # Older variant
â”œâ”€â”€ video2caption_v1.0_not_work.py # Explicitly marked non-working legacy file
â”œâ”€â”€ training.py                    # Model training entrypoint
â”œâ”€â”€ evaluate.py                    # Test-split evaluation and rendered outputs
â”œâ”€â”€ dataset_generation.py          # Builds data/processed/dataset.pkl
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ dataset.py                 # Dataset + DataLoader helpers
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ model.py                   # CLIP encoder + mapping + GPT2 decoder
â”‚   â””â”€â”€ trainer.py                 # Training/validation/test utility class
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                  # ConfigS / ConfigL defaults
â”‚   â”œâ”€â”€ downloads.py               # Google Drive checkpoint downloader
â”‚   â””â”€â”€ lr_warmup.py               # LR warmup schedule
â”œâ”€â”€ i18n/                          # Multilingual README variants
â””â”€â”€ .auto-readme-work/             # Auto-README pipeline artifacts
```

## ğŸ“‹ å‰ææ¡ä»¶

- Python `3.10+` ã‚’æ¨å¥¨ã€‚
- å­¦ç¿’ã¨å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«æ¨è«–ã§ã¯ CUDA å¯¾å¿œ GPU ãŒæœ›ã¾ã—ã„ã§ã™ãŒã€å¿…é ˆã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚
- ç¾è¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆã§ã¯ `ffmpeg` ã¯ç›´æ¥å¿…è¦ã‚ã‚Šã¾ã›ã‚“ï¼ˆãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºã¯ OpenCVï¼‰ã€‚
- Hugging Face / Google Drive ã‹ã‚‰åˆå›ãƒ¢ãƒ‡ãƒ«ãƒ»ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’å–å¾—ã™ã‚‹éš›ã«ã€ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶šãŒå¿…è¦ã§ã™ã€‚

ç¾åœ¨ã€ãƒ­ãƒƒã‚¯ãƒ•ã‚¡ã‚¤ãƒ«ã¯å­˜åœ¨ã—ã¾ã›ã‚“ï¼ˆ`requirements.txt` / `pyproject.toml` ãŒæœªé…ç½®ï¼‰ãŸã‚ã€ä¾å­˜é–¢ä¿‚ã¯ import ã‹ã‚‰æ¨å®šã•ã‚Œã¾ã™ã€‚

## ğŸ› ï¸ ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

### ç¾è¡Œãƒªãƒã‚¸ãƒˆãƒªæ§‹æˆã«æ²¿ã£ãŸå…¬å¼æ‰‹é †

```bash
git clone git@github.com:lachlanchen/VideoCaptionerWithClip.git
cd VideoCaptionerWithClip

python -m venv .venv
source .venv/bin/activate

pip install --upgrade pip
pip install torch torchvision torchaudio
pip install transformers pillow matplotlib numpy tqdm opencv-python pandas wandb gdown
```

### å…ƒ README ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ–­ç‰‡ï¼ˆä¿ç®¡ï¼‰

ä»¥å‰ã® README ã¯é€”ä¸­ã§é€”åˆ‡ã‚Œã¦ã„ãŸãŸã‚ã€ã‚½ãƒ¼ã‚¹ãƒ»ã‚ªãƒ–ãƒ»ãƒˆã‚¥ãƒ«ãƒ¼ã‚¹ã¨ã—ã¦å±¥æ­´ã®ã‚³ãƒãƒ³ãƒ‰ã‚’ãã®ã¾ã¾æ®‹ã—ã¦ã„ã¾ã™ã€‚

```bash
git clone git@github.com:lachlanchen/VideoCaptionerWithClip.git
cd VideoCaptionerWithClip/src
```

æ³¨è¨˜: ç¾åœ¨ã®ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã§ã¯ã‚¹ã‚¯ãƒªãƒ—ãƒˆãŒãƒªãƒã‚¸ãƒˆãƒªç›´ä¸‹ã«ã‚ã‚Šã€`src/` é…ä¸‹ã«ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚

## â–¶ï¸ Quick Start

| ç›®çš„ | ã‚³ãƒãƒ³ãƒ‰ |
|---|---|
| ç”»åƒã‚’ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã™ã‚‹ | `python image2caption.py -I /path/to/image.jpg -S L -C model.pt` |
| å‹•ç”»ã‚’ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã™ã‚‹ | `python v2c.py -V /path/to/video.mp4 -N 10` |
| ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ§‹ç¯‰ã™ã‚‹ | `python dataset_generation.py` |

### ç”»åƒã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ï¼ˆç°¡æ˜“ï¼‰

```bash
python image2caption.py -I /path/to/image.jpg -S L -C model.pt
```

### å‹•ç”»ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ï¼ˆæ¨å¥¨ï¼‰

```bash
python v2c.py -V /path/to/video.mp4 -N 10
```

## ğŸ¯ åˆ©ç”¨æ–¹æ³•

### 1. ç”»åƒã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ (`image2caption.py`)

```bash
python image2caption.py \
  -I /path/to/image.jpg \
  -S L \
  -C model.pt \
  -R ./data/result/prediction \
  -T 1.0
```

å¼•æ•°:

- `-I, --img-path`: å…¥åŠ›ç”»åƒã®ãƒ‘ã‚¹ã€‚
- `-S, --size`: ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºï¼ˆ`S` ã¾ãŸã¯ `L`ï¼‰ã€‚
- `-C, --checkpoint-name`: `weights/{small|large}` å†…ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆåã€‚
- `-R, --res-path`: ç”Ÿæˆç”»åƒã®ä¿å­˜å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã€‚
- `-T, --temperature`: ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ¸©åº¦ã€‚

### 2. ä»£æ›¿ç”»åƒ CLI (`predict.py`)

```bash
python predict.py \
  -I /path/to/image.jpg \
  -S L \
  -C model.pt \
  -R ./data/result/prediction \
  -T 1.0
```

`predict.py` ã¯ `image2caption.py` ã¨æ©Ÿèƒ½çš„ã«ã¯ã»ã¼åŒç­‰ã§ã™ãŒã€ãƒ†ã‚­ã‚¹ãƒˆã®æ•´å½¢å½¢å¼ãŒã‚ãšã‹ã«ç•°ãªã‚Šã¾ã™ã€‚

### 3. ç”»åƒã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ç”¨ã‚¯ãƒ©ã‚¹ API (`i2c.py`)

```bash
python i2c.py -I /path/to/image.jpg -S L -C model.pt -R ./data/result/prediction -T 1.0
```

ã¾ãŸã¯ç‹¬è‡ªã‚¹ã‚¯ãƒªãƒ—ãƒˆã§ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¾ã™ã€‚

```python
from i2c import ImageCaptioner

captioner = ImageCaptioner(model_size="L", checkpoint_name="model.pt")
captioner.set_image_path("/path/to/image.jpg")
caption = captioner.generate_caption(save_image=True)
print(caption)
```

### 4. å‹•ç”»â†’å­—å¹• + JSON (`v2c.py`)

```bash
python v2c.py -V /path/to/video.mp4 -N 10
```

å…¥åŠ›å‹•ç”»ã®éš£ã«ä»¥ä¸‹ã‚’å‡ºåŠ›ã—ã¾ã™ã€‚

- `<video_basename>_caption.srt`
- `<video_basename>_caption.json`
- `<video_basename>_captioning_frames/`

### 5. ä»£æ›¿å‹•ç”»ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ (`video2caption.py`)

```bash
python video2caption.py -V /path/to/video.mp4 -N 10
```

é‡è¦: ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã«ã¯ç¾åœ¨ã€ãƒã‚·ãƒ³å›ºæœ‰ã®ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ãƒ‘ã‚¹ãŒå«ã¾ã‚Œã¾ã™ã€‚

- Python ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ã‚¹: `/home/lachlan/miniconda3/envs/caption/bin/python`
- ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆãƒ‘ã‚¹: `/home/lachlan/Projects/image_captioning/clip-gpt-captioning/src/image2caption.py`

ã“ã‚Œã‚‰ã®ãƒ‘ã‚¹ã‚’ç¶­æŒã—ãŸã¾ã¾ä½¿ç”¨ã™ã‚‹å ´åˆã‚’é™¤ãã€`v2c.py` ã‚’ä½¿ã£ã¦ãã ã•ã„ã€‚

### 6. ãƒ¬ã‚¬ã‚·ãƒ¼ç‰ˆ (`video2caption_v1.1.py`)

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯å±¥æ­´å‚ç…§ç”¨ã«ä¿æŒã•ã‚Œã¦ã„ã¾ã™ã€‚å®Ÿé‹ç”¨ã§ã¯ `v2c.py` ã‚’æ¨å¥¨ã—ã¾ã™ã€‚

### 7. ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç”Ÿæˆ

```bash
python dataset_generation.py
```

æƒ³å®šå…¥åŠ›:

- `data/raw/results.csv`ï¼ˆ`|` åŒºåˆ‡ã‚Šã®ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³è¡¨ï¼‰
- `data/raw/flickr30k_images/`ï¼ˆCSV ãŒå‚ç…§ã™ã‚‹ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ï¼‰

å‡ºåŠ›:

- `data/processed/dataset.pkl`

### 8. å­¦ç¿’

```bash
python training.py -S L -C model.pt
```

å­¦ç¿’æ™‚ã«ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ Weights & Biasesï¼ˆ`wandb`ï¼‰ã®ãƒ­ã‚®ãƒ³ã‚°ãŒæœ‰åŠ¹ã§ã™ã€‚

### 9. è©•ä¾¡

```bash
python evaluate.py \
  -I ./data/raw/flickr30k_images \
  -R ./data/result/eval \
  -S L \
  -C model.pt \
  -T 1.0
```

è©•ä¾¡ã§ã¯ãƒ†ã‚¹ãƒˆç”»åƒã«å¯¾ã—ã¦äºˆæ¸¬ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã‚’ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ã—ã€ä»¥ä¸‹ã¸ä¿å­˜ã—ã¾ã™ã€‚

- `<res-path>/<checkpoint_name_without_ext>_<SIZE>/`

## âš™ï¸ è¨­å®š

ãƒ¢ãƒ‡ãƒ«è¨­å®šã¯ `utils/config.py` ã«å®šç¾©ã•ã‚Œã¦ã„ã¾ã™ã€‚

| è¨­å®š | CLIP ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³ | GPT ãƒ¢ãƒ‡ãƒ« | é‡ã¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª |
|---|---|---|---|
| `ConfigS` | `openai/clip-vit-base-patch32` | `gpt2` | `weights/small` |
| `ConfigL` | `openai/clip-vit-large-patch14` | `gpt2-medium` | `weights/large` |

è¨­å®šã‚¯ãƒ©ã‚¹ã®ä¸»è¦ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ:

| é …ç›® | `ConfigS` | `ConfigL` |
|---|---:|---:|
| `epochs` | 150 | 120 |
| `lr` | 3e-3 | 5e-3 |
| `batch_size_exp` | 6 | 5 |
| `ep_len` | 4 | 4 |
| `max_len` | 40 | 40 |

ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆè‡ªå‹•ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ ID ã¯ `utils/downloads.py` ã«ã‚ã‚Šã¾ã™ã€‚

| ã‚µã‚¤ã‚º | Google Drive ID |
|---|---|
| `L` | `1Gh32arzhW06C1ZJyzcJSSfdJDi3RgWoG` |
| `S` | `1pSQruQyg8KJq6VmzhMLFbT_VaHJMdlWF` |

## ğŸ“¦ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«

### ç”»åƒæ¨è«–

- `--res-path` ã«ã€ä¸Šã«æ–‡å­—ãŒé‡ç•³ã•ã‚ŒãŸç”Ÿæˆç”»åƒã‚’ä¿å­˜ã€‚
- ãƒ•ã‚¡ã‚¤ãƒ«å: `<input_stem>-R<SIZE>.jpg`

### å‹•ç”»æ¨è«– (`v2c.py`)

- SRT: `<video_stem>_caption.srt`
- JSON: `<video_stem>_caption.json`
- ãƒ•ãƒ¬ãƒ¼ãƒ ç”»åƒ: `<video_stem>_captioning_frames/`

JSON è¦ç´ ä¾‹:

```json
{
  "start": "00:00:03,200",
  "end": "00:00:03,700",
  "lang": "en",
  "text": "A dog running through a field."
}
```

## ğŸ§ª ä½¿ç”¨ä¾‹

### ç”»åƒã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ï¼ˆç°¡æ˜“ï¼‰

```bash
python image2caption.py -I ./examples/dog.jpg -S S -C model.pt
```

æƒ³å®šã•ã‚Œã‚‹æŒ™å‹•:

- `weights/small/model.pt` ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã€è‡ªå‹•ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã™ã€‚
- ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ç”»åƒã¯æ—¢å®šã§ `./data/result/prediction` ã«ä¿å­˜ã•ã‚Œã¾ã™ã€‚
- ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³æ–‡ã¯æ¨™æº–å‡ºåŠ›ã¸è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚

### å‹•ç”»ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ï¼ˆç°¡æ˜“ï¼‰

```bash
python v2c.py -V ./examples/demo.mp4 -N 8
```

æƒ³å®šã•ã‚Œã‚‹æŒ™å‹•:

- 8 æšã®å‡ä¸€ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ•ãƒ¬ãƒ¼ãƒ ã«å¯¾ã—ã¦ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆã€‚
- å…¥åŠ›å‹•ç”»ã®éš£ã« `.srt` ã¨ `.json` ãŒç”Ÿæˆã•ã‚Œã¾ã™ã€‚

### å­¦ç¿’ãƒ»è©•ä¾¡ã®ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ã‚·ãƒ¼ã‚±ãƒ³ã‚¹

```bash
python dataset_generation.py
python training.py -S L -C model.pt
python evaluate.py -I ./data/raw/flickr30k_images -R ./data/result/eval -S L -C model.pt -T 1.0
```

## ğŸ§­ é–‹ç™ºãƒãƒ¼ãƒˆ

- `v2c.py`ã€`video2caption.py`ã€`video2caption_v1.*` ã®é–“ã§é‡è¤‡å®Ÿè£…ãŒæ®‹ã£ã¦ã„ã¾ã™ã€‚
- `video2caption_v1.0_not_work.py` ã¯æ„å›³çš„ã«éå‹•ä½œã®ãƒ¬ã‚¬ã‚·ãƒ¼ã‚³ãƒ¼ãƒ‰ã¨ã—ã¦ä¿æŒã€‚
- `training.py` ã¯ `config = ConfigL() if args.size.upper() else ConfigS()` ã§ `--size` ãŒç©ºã§ãªã„é™ã‚Šå¸¸ã« `ConfigL` ã‚’é¸ã³ã¾ã™ã€‚
- `model/trainer.py` ã¯ `test_step` ã§ `self.dataset` ã‚’å‚ç…§ã—ã¾ã™ãŒã€åˆæœŸåŒ–ã§ã¯ `self.test_dataset` ã‚’ä»£å…¥ã—ã¦ã„ã‚‹ãŸã‚ã€èª¿æ•´ã—ãªã„ã¨å­¦ç¿’æ™‚ã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãŒå´©ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚
- `video2caption_v1.1.py` ã¯ `self.config.transform` ã‚’å‚ç…§ã—ã¾ã™ãŒã€`ConfigS` / `ConfigL` ã¯ `transform` ã‚’å®šç¾©ã—ã¦ã„ã¾ã›ã‚“ã€‚
- ã“ã®ãƒªãƒã‚¸ãƒˆãƒªã®ç¾åœ¨ã®ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã§ã¯ CI/test suite ãŒæœªå®šç¾©ã§ã™ã€‚
- i18n ãƒ¡ãƒ¢: è¨€èªãƒªãƒ³ã‚¯ã¯ã“ã® README å†’é ­ã«ã‚ã‚Šã¾ã™ã€‚ç¿»è¨³ãƒ•ã‚¡ã‚¤ãƒ«ã¯ `i18n/` é…ä¸‹ã«è¿½åŠ ã§ãã¾ã™ã€‚
- ç¾åœ¨ã®çŠ¶æ…‹ãƒ¡ãƒ¢: è¨€èªãƒãƒ¼ãŒ `i18n/README.ru.md` ã‚’å‚ç…§ã—ã¦ã„ã¾ã™ãŒã€ã“ã®ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã«ã¯è©²å½“ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“ã€‚

## ğŸ©º ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

- `AssertionError: Image does not exist`
  - `-I/--img-path` ãŒæœ‰åŠ¹ãªãƒ•ã‚¡ã‚¤ãƒ«ã‚’æŒ‡ã—ã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚
- `Dataset file not found. Downloading...`
  - `MiniFlickrDataset` ã¯ `data/processed/dataset.pkl` ãŒãªã„å ´åˆã«ã“ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å‡ºã—ã€`python dataset_generation.py` ã‚’å…ˆã«å®Ÿè¡Œã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚
- `Path to the test image folder does not exist`
  - `evaluate.py -I` ãŒæ—¢å­˜ãƒ•ã‚©ãƒ«ãƒ€ã‚’æŒ‡ã—ã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚
- åˆå›èµ·å‹•ãŒé…ã„ï¼å¤±æ•—ã™ã‚‹
  - åˆå›ã¯ Hugging Face ã®ãƒ¢ãƒ‡ãƒ«å–å¾—ã¨ Google Drive ã‹ã‚‰ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆå–å¾—ãŒç™ºç”Ÿã™ã‚‹ãŸã‚ã§ã™ã€‚
- `video2caption.py` ãŒç©ºã®ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã‚’è¿”ã™
  - ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ãƒ‘ã‚¹ã‚„ Python å®Ÿè¡Œãƒ‘ã‚¹ã‚’ç¢ºèªã™ã‚‹ã‹ã€`v2c.py` ã«åˆ‡ã‚Šæ›¿ãˆã¦ãã ã•ã„ã€‚
- `wandb` ãŒå­¦ç¿’æ™‚ã«ãƒ­ã‚°ã‚¤ãƒ³ã‚’è¦æ±‚ã™ã‚‹
  - `wandb login` ã‚’å®Ÿè¡Œã™ã‚‹ã‹ã€å¿…è¦ã«å¿œã˜ã¦ `training.py` ã§ãƒ­ã‚®ãƒ³ã‚°ã‚’æ‰‹å‹•ã§ç„¡åŠ¹åŒ–ã—ã¦ãã ã•ã„ã€‚

## ğŸ›£ï¸ Roadmap

- å†ç¾æ€§ã‚’é«˜ã‚ã‚‹ãŸã‚ä¾å­˜ãƒ­ãƒƒã‚¯ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ`requirements.txt` ã¾ãŸã¯ `pyproject.toml`ï¼‰ã‚’è¿½åŠ ã€‚
- é‡è¤‡ã—ãŸå‹•ç”»ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ 1 ã¤ã«çµ±åˆã—ã€ç¶­æŒå¯¾è±¡ã‚’ä¸€æœ¬åŒ–ã€‚
- ãƒ¬ã‚¬ã‚·ãƒ¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®æ©Ÿæä¾å­˜ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ãƒ‘ã‚¹ã‚’é™¤å»ã€‚
- `training.py` ã¨ `model/trainer.py` ã®æ—¢çŸ¥ã®å­¦ç¿’ãƒ»è©•ä¾¡ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ä¸å…·åˆã‚’ä¿®æ­£ã€‚
- è‡ªå‹•ãƒ†ã‚¹ãƒˆã¨ CI ã‚’è¿½åŠ ã€‚
- è¨€èªãƒãƒ¼ã§å‚ç…§ã•ã‚Œã‚‹ `i18n/` é…ä¸‹ã® README ã‚’ç¿»è¨³ç‰ˆã§æƒãˆã‚‹ã€‚

## ğŸ¤ Contributing

ã‚³ãƒ³ãƒˆãƒªãƒ“ãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã¯æ­“è¿ã—ã¾ã™ã€‚æ¨å¥¨ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼:

```bash
# 1) Fork and clone
git clone git@github.com:<your-user>/VideoCaptionerWithClip.git
cd VideoCaptionerWithClip

# 2) Create a feature branch
git checkout -b feat/your-change

# 3) Make changes and commit
git add .
git commit -m "feat: describe your change"

# 4) Push and open a PR
git push origin feat/your-change
```

ãƒ¢ãƒ‡ãƒ«æŒ™å‹•ã‚’å¤‰æ›´ã™ã‚‹å ´åˆã¯ä»¥ä¸‹ã‚’å«ã‚ã¦ãã ã•ã„ã€‚

- å†ç¾å¯èƒ½ãªã‚³ãƒãƒ³ãƒ‰ã€‚
- å¤‰æ›´å‰å¾Œã®ã‚µãƒ³ãƒ—ãƒ«å‡ºåŠ›ã€‚
- ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã¾ãŸã¯ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®å‰ææ¡ä»¶ãƒ¡ãƒ¢ã€‚

---

## â¤ï¸ Support

| Donate | PayPal | Stripe |
| --- | --- | --- |
| [![Donate](https://camo.githubusercontent.com/24a4914f0b42c6f435f9e101621f1e52535b02c225764b2f6cc99416926004b7/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f446f6e6174652d4c617a79696e674172742d3045413545393f7374796c653d666f722d7468652d6261646765266c6f676f3d6b6f2d6669266c6f676f436f6c6f723d7768697465)](https://chat.lazying.art/donate) | [![PayPal](https://camo.githubusercontent.com/d0f57e8b016517a4b06961b24d0ca87d62fdba16e18bbdb6aba28e978dc0ea21/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f50617950616c2d526f6e677a686f754368656e2d3030343537433f7374796c653d666f722d7468652d6261646765266c6f676f3d70617970616c266c6f676f436f6c6f723d7768697465)](https://paypal.me/RongzhouChen) | [![Stripe](https://camo.githubusercontent.com/1152dfe04b6943afe3a8d2953676749603fb9f95e24088c92c97a01a897b4942/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f5374726970652d446f6e6174652d3633354246463f7374796c653d666f722d7468652d6261646765266c6f676f3d737472697065266c6f676f436f6c6f723d7768697465)](https://buy.stripe.com/aFadR8gIaflgfQV6T4fw400) |

## ğŸ“„ License

ç¾åœ¨ã®ãƒªãƒã‚¸ãƒˆãƒªã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã«ã¯ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“ã€‚

æ³¨è¨˜: `LICENSE` ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¿½åŠ ã•ã‚Œã‚‹ã¾ã§ã¯ã€å†åˆ©ç”¨ãƒ»å†é…å¸ƒã®æ¡ä»¶ã¯æœªå®šç¾©ã§ã™ã€‚

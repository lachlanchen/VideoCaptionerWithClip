[English](../README.md) ¬∑ [ÿßŸÑÿπÿ±ÿ®Ÿäÿ©](README.ar.md) ¬∑ [Espa√±ol](README.es.md) ¬∑ [Fran√ßais](README.fr.md) ¬∑ [Êó•Êú¨Ë™û](README.ja.md) ¬∑ [ÌïúÍµ≠Ïñ¥](README.ko.md) ¬∑ [Ti·∫øng Vi·ªát](README.vi.md) ¬∑ [‰∏≠Êñá (ÁÆÄ‰Ωì)](README.zh-Hans.md) ¬∑ [‰∏≠ÊñáÔºàÁπÅÈ´îÔºâ](README.zh-Hant.md) ¬∑ [Deutsch](README.de.md) ¬∑ [–†—É—Å—Å–∫–∏–π](README.ru.md)


# Clip-GPT-Captioning

![Python](https://img.shields.io/badge/Python-3.10%2B-blue)
![PyTorch](https://img.shields.io/badge/PyTorch-2.x-red)
![Transformers](https://img.shields.io/badge/HuggingFace-Transformers-yellow)
![Status](https://img.shields.io/badge/README-Expanded-success)
![Repo Layout](https://img.shields.io/badge/Layout-Root%20Scripts-informational)
![Legacy Scripts](https://img.shields.io/badge/Legacy%20Scripts-Present-orange)
![i18n](https://img.shields.io/badge/i18n-Enabled-brightgreen)
![Maintained Path](https://img.shields.io/badge/Video-v2c.py-2ea44f)

Python-–∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞—Ä–∏–π –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –æ–ø–∏—Å–∞–Ω–∏–π –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ –≤–∏–¥–µ–æ —Å –ø–æ–º–æ—â—å—é –≤–∏–∑—É–∞–ª—å–Ω—ã—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ OpenAI CLIP –∏ —è–∑—ã–∫–æ–≤–æ–π –º–æ–¥–µ–ª–∏ –≤ —Å—Ç–∏–ª–µ GPT.

## ‚ú® –û–±–∑–æ—Ä

–≠—Ç–æ—Ç —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç:

- –°–∫—Ä–∏–ø—Ç—ã –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ –¥–ª—è –æ–ø–∏—Å–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å—É–±—Ç–∏—Ç—Ä–æ–≤ –¥–ª—è –≤–∏–¥–µ–æ.
- –ü–∞–π–ø–ª–∞–π–Ω –æ–±—É—á–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–π –∏–∑—É—á–∞–µ—Ç –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤–∏–∑—É–∞–ª—å–Ω—ã—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ CLIP –≤ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ —Ç–æ–∫–µ–Ω–æ–≤ GPT-2.
- –£—Ç–∏–ª–∏—Ç—ã –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞ –≤ —Å—Ç–∏–ª–µ Flickr30k.
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫—É—é –∑–∞–≥—Ä—É–∑–∫—É checkpoint-—Ñ–∞–π–ª–æ–≤ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã—Ö —Ä–∞–∑–º–µ—Ä–æ–≤ –º–æ–¥–µ–ª–∏ –ø—Ä–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ –≤–µ—Å–æ–≤.
- –ú—É–ª—å—Ç–∏—è–∑—ã—á–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã README –≤ `i18n/` (—Å–º. —è–∑—ã–∫–æ–≤—É—é —Å—Ç—Ä–æ–∫—É –≤—ã—à–µ).

–¢–µ–∫—É—â–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è –≤–∫–ª—é—á–∞–µ—Ç –∫–∞–∫ –Ω–æ–≤—ã–µ, —Ç–∞–∫ –∏ legacy-—Å–∫—Ä–∏–ø—Ç—ã. –ù–µ–∫–æ—Ç–æ—Ä—ã–µ legacy-—Ñ–∞–π–ª—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –¥–ª—è —Å–ø—Ä–∞–≤–∫–∏ –∏ –∑–∞–¥–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω—ã –Ω–∏–∂–µ.

## üöÄ –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏

- –û–ø–∏—Å–∞–Ω–∏–µ –æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —á–µ—Ä–µ–∑ `image2caption.py`.
- –û–ø–∏—Å–∞–Ω–∏–µ –≤–∏–¥–µ–æ (—Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞ –∫–∞–¥—Ä–æ–≤) —á–µ—Ä–µ–∑ `v2c.py` –∏–ª–∏ `video2caption.py`.
- –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º—ã–µ runtime-–ø–∞—Ä–∞–º–µ—Ç—Ä—ã:
  - –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–¥—Ä–æ–≤.
  - –†–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏.
  - –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ —Å–µ–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏—è.
  - –ò–º—è checkpoint-—Ñ–∞–π–ª–∞.
- –ú–Ω–æ–≥–æ–ø—Ä–æ—Ü–µ—Å—Å–Ω–∞—è/–º–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ–¥–ø–∏—Å–µ–π –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ –≤–∏–¥–µ–æ.
- –í—ã—Ö–æ–¥–Ω—ã–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã:
  - –§–∞–π–ª—ã —Å—É–±—Ç–∏—Ç—Ä–æ–≤ SRT (`.srt`).
  - JSON-—Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç—ã (`.json`) –≤ `v2c.py`.
- –¢–æ—á–∫–∏ –≤—Ö–æ–¥–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∏ –æ—Ü–µ–Ω–∫–∏ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ –ø–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—é CLIP+GPT2.

### –ö—Ä–∞—Ç–∫–æ

| –û–±–ª–∞—Å—Ç—å | –û—Å–Ω–æ–≤–Ω–æ–π(—ã–µ) —Å–∫—Ä–∏–ø—Ç(—ã) | –ü—Ä–∏–º–µ—á–∞–Ω–∏—è |
|---|---|---|
| –û–ø–∏—Å–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π | `image2caption.py`, `i2c.py`, `predict.py` | CLI + –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–π –∫–ª–∞—Å—Å |
| –û–ø–∏—Å–∞–Ω–∏–µ –≤–∏–¥–µ–æ | `v2c.py` | –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π –ø—É—Ç—å |
| Legacy-–ø–∞–π–ø–ª–∞–π–Ω –≤–∏–¥–µ–æ | `video2caption.py`, `video2caption_v1.1.py` | –°–æ–¥–µ—Ä–∂–∏—Ç machine-specific –¥–æ–ø—É—â–µ–Ω–∏—è |
| –°–±–æ—Ä–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ | `dataset_generation.py` | –°–æ–∑–¥–∞–µ—Ç `data/processed/dataset.pkl` |
| –û–±—É—á–µ–Ω–∏–µ / –æ—Ü–µ–Ω–∫–∞ | `training.py`, `evaluate.py` | –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ CLIP+GPT2 |

## üß± –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ (–≤—ã—Å–æ–∫–æ—É—Ä–æ–≤–Ω–µ–≤–æ)

–ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å –≤ `model/model.py` —Å–æ—Å—Ç–æ–∏—Ç –∏–∑ —Ç—Ä–µ—Ö —á–∞—Å—Ç–µ–π:

1. `ImageEncoder`: –∏–∑–≤–ª–µ–∫–∞–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è CLIP.
2. `Mapping`: –ø—Ä–æ–µ—Ü–∏—Ä—É–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥ CLIP –≤ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å prefix-—ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ GPT.
3. `TextDecoder`: head —è–∑—ã–∫–æ–≤–æ–π –º–æ–¥–µ–ª–∏ GPT-2, –∫–æ—Ç–æ—Ä—ã–π –∞–≤—Ç–æ—Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω–æ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç–æ–∫–µ–Ω—ã –ø–æ–¥–ø–∏—Å–∏.

–û–±—É—á–µ–Ω–∏–µ (`Net.train_forward`) –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –ø—Ä–µ–¥–≤—ã—á–∏—Å–ª–µ–Ω–Ω—ã–µ CLIP-—ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π + —Ç–æ–∫–µ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–æ–¥–ø–∏—Å–∏.
–ò–Ω—Ñ–µ—Ä–µ–Ω—Å (`Net.forward`) –∏—Å–ø–æ–ª—å–∑—É–µ—Ç PIL-–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏ –¥–µ–∫–æ–¥–∏—Ä—É–µ—Ç —Ç–æ–∫–µ–Ω—ã –¥–æ EOS –∏–ª–∏ `max_len`.

### –ü–æ—Ç–æ–∫ –¥–∞–Ω–Ω—ã—Ö

1. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞: `dataset_generation.py` —á–∏—Ç–∞–µ—Ç `data/raw/results.csv` –∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ `data/raw/flickr30k_images/`, –∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç `data/processed/dataset.pkl`.
2. –û–±—É—á–µ–Ω–∏–µ: `training.py` –∑–∞–≥—Ä—É–∂–∞–µ—Ç —Å–µ—Ä–∏–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –∫–æ—Ä—Ç–µ–∂–∏ `(image_name, image_embedding, caption)` –∏ –æ–±—É—á–∞–µ—Ç —Å–ª–æ–∏ mapper/decoder.
3. –û—Ü–µ–Ω–∫–∞: `evaluate.py` –≤–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–æ–¥–ø–∏—Å–∏ –Ω–∞ –æ—Ç–ª–æ–∂–µ–Ω–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö.
4. –ò–Ω—Ñ–µ—Ä–µ–Ω—Å:
   - image: `image2caption.py` / `predict.py` / `i2c.py`.
   - video: `v2c.py` (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è), `video2caption.py` (legacy).

## üóÇÔ∏è –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞

```text
VideoCaptionerWithClip/
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ image2caption.py               # Single-image caption CLI
‚îú‚îÄ‚îÄ predict.py                     # Alternate single-image caption CLI
‚îú‚îÄ‚îÄ i2c.py                         # Reusable ImageCaptioner class + CLI
‚îú‚îÄ‚îÄ v2c.py                         # Video -> SRT + JSON (threaded frame captioning)
‚îú‚îÄ‚îÄ video2caption.py               # Alternate video -> SRT implementation (legacy constraints)
‚îú‚îÄ‚îÄ video2caption_v1.1.py          # Older variant
‚îú‚îÄ‚îÄ video2caption_v1.0_not_work.py # Explicitly marked non-working legacy file
‚îú‚îÄ‚îÄ training.py                    # Model training entrypoint
‚îú‚îÄ‚îÄ evaluate.py                    # Test-split evaluation and rendered outputs
‚îú‚îÄ‚îÄ dataset_generation.py          # Builds data/processed/dataset.pkl
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ dataset.py                 # Dataset + DataLoader helpers
‚îú‚îÄ‚îÄ model/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ model.py                   # CLIP encoder + mapping + GPT2 decoder
‚îÇ   ‚îî‚îÄ‚îÄ trainer.py                 # Training/validation/test utility class
‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ config.py                  # ConfigS / ConfigL defaults
‚îÇ   ‚îú‚îÄ‚îÄ downloads.py               # Google Drive checkpoint downloader
‚îÇ   ‚îî‚îÄ‚îÄ lr_warmup.py               # LR warmup schedule
‚îú‚îÄ‚îÄ i18n/                          # Multilingual README variants
‚îî‚îÄ‚îÄ .auto-readme-work/             # Auto-README pipeline artifacts
```

## üìã –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è

- –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è Python `3.10+`.
- GPU —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π CUDA –Ω–µ –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω, –Ω–æ –Ω–∞—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∏ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ –±–æ–ª—å—à–∏—Ö –º–æ–¥–µ–ª–µ–π.
- `ffmpeg` –Ω–∞–ø—Ä—è–º—É—é –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è —Ç–µ–∫—É—â–∏–º–∏ —Å–∫—Ä–∏–ø—Ç–∞–º–∏ (–¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∫–∞–¥—Ä–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è OpenCV).
- –ò–Ω—Ç–µ—Ä–Ω–µ—Ç-–¥–æ—Å—Ç—É–ø –Ω—É–∂–µ–Ω –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—É—Å–∫–µ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–µ–π/checkpoint-—Ñ–∞–π–ª–æ–≤ –∏–∑ Hugging Face / Google Drive.

–í –ø—Ä–æ–µ–∫—Ç–µ –ø–æ–∫–∞ –Ω–µ—Ç lockfile (`requirements.txt` / `pyproject.toml` –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç), –ø–æ—ç—Ç–æ–º—É –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ–ø—Ä–µ–¥–µ–ª—è—é—Ç—Å—è –ø–æ –∏–º–ø–æ—Ä—Ç–∞–º.

## üõ†Ô∏è –£—Å—Ç–∞–Ω–æ–≤–∫–∞

### –ö–∞–Ω–æ–Ω–∏—á–Ω–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –¥–ª—è —Ç–µ–∫—É—â–µ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è

```bash
git clone git@github.com:lachlanchen/VideoCaptionerWithClip.git
cd VideoCaptionerWithClip

python -m venv .venv
source .venv/bin/activate

pip install --upgrade pip
pip install torch torchvision torchaudio
pip install transformers pillow matplotlib numpy tqdm opencv-python pandas wandb gdown
```

### –§—Ä–∞–≥–º–µ–Ω—Ç —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –∏–∑ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ README (—Å–æ—Ö—Ä–∞–Ω–µ–Ω)

–ü—Ä–µ–¥—ã–¥—É—â–∏–π README –æ–±—Ä—ã–≤–∞–ª—Å—è –Ω–∞ —Å–µ—Ä–µ–¥–∏–Ω–µ –±–ª–æ–∫–∞. –ò—Å—Ö–æ–¥–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –Ω–∏–∂–µ –≤ —Ç–æ—á–Ω–æ—Å—Ç–∏ –∫–∞–∫ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–π –ø–µ—Ä–≤–æ–∏—Å—Ç–æ—á–Ω–∏–∫:

```bash
git clone git@github.com:lachlanchen/VideoCaptionerWithClip.git
cd VideoCaptionerWithClip/src
```

–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ: –≤ —Ç–µ–∫—É—â–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è —Å–∫—Ä–∏–ø—Ç—ã —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω—ã –≤ –∫–æ—Ä–Ω–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è, –∞ –Ω–µ –≤ `src/`.

## ‚ñ∂Ô∏è –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

### –û–ø–∏—Å–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–±—ã—Å—Ç—Ä—ã–π –∑–∞–ø—É—Å–∫)

```bash
python image2caption.py -I /path/to/image.jpg -S L -C model.pt
```

### –û–ø–∏—Å–∞–Ω–∏–µ –≤–∏–¥–µ–æ (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π –ø—É—Ç—å)

```bash
python v2c.py -V /path/to/video.mp4 -N 10
```

## üéØ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

### 1. –û–ø–∏—Å–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (`image2caption.py`)

```bash
python image2caption.py \
  -I /path/to/image.jpg \
  -S L \
  -C model.pt \
  -R ./data/result/prediction \
  -T 1.0
```

–ê—Ä–≥—É–º–µ–Ω—Ç—ã:

- `-I, --img-path`: –ø—É—Ç—å –∫ –≤—Ö–æ–¥–Ω–æ–º—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é.
- `-S, --size`: —Ä–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏ (`S` –∏–ª–∏ `L`).
- `-C, --checkpoint-name`: –∏–º—è checkpoint-—Ñ–∞–π–ª–∞ –≤ `weights/{small|large}`.
- `-R, --res-path`: –≤—ã—Ö–æ–¥–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –æ—Ç—Ä–∏—Å–æ–≤–∞–Ω–Ω–æ–π –ø–æ–¥–ø–∏—Å—å—é.
- `-T, --temperature`: —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ —Å–µ–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏—è.

### 2. –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π image CLI (`predict.py`)

```bash
python predict.py \
  -I /path/to/image.jpg \
  -S L \
  -C model.pt \
  -R ./data/result/prediction \
  -T 1.0
```

`predict.py` —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –ø–æ—Ö–æ–∂ –Ω–∞ `image2caption.py`; —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –Ω–µ–º–Ω–æ–≥–æ –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è.

### 3. API –∫–ª–∞—Å—Å–∞ –¥–ª—è –æ–ø–∏—Å–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (`i2c.py`)

```bash
python i2c.py -I /path/to/image.jpg -S L -C model.pt -R ./data/result/prediction -T 1.0
```

–ò–ª–∏ –∏–º–ø–æ—Ä—Ç–∏—Ä—É–π—Ç–µ –≤ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–π —Å–∫—Ä–∏–ø—Ç:

```python
from i2c import ImageCaptioner

captioner = ImageCaptioner(model_size="L", checkpoint_name="model.pt")
captioner.set_image_path("/path/to/image.jpg")
caption = captioner.generate_caption(save_image=True)
print(caption)
```

### 4. –í–∏–¥–µ–æ –≤ —Å—É–±—Ç–∏—Ç—Ä—ã + JSON (`v2c.py`)

```bash
python v2c.py -V /path/to/video.mp4 -N 10
```

–í—ã—Ö–æ–¥–Ω—ã–µ —Ñ–∞–π–ª—ã —Ä—è–¥–æ–º —Å –≤—Ö–æ–¥–Ω—ã–º –≤–∏–¥–µ–æ:

- `<video_basename>_caption.srt`
- `<video_basename>_caption.json`
- `<video_basename>_captioning_frames/`

### 5. –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π video-–ø–∞–π–ø–ª–∞–π–Ω (`video2caption.py`)

```bash
python video2caption.py -V /path/to/video.mp4 -N 10
```

–í–∞–∂–Ω–æ: —ç—Ç–æ—Ç —Å–∫—Ä–∏–ø—Ç —Å–µ–π—á–∞—Å —Å–æ–¥–µ—Ä–∂–∏—Ç machine-specific hardcoded –ø—É—Ç–∏:

- Python path –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: `/home/lachlan/miniconda3/envs/caption/bin/python`
- –ü—É—Ç—å –∫ —Å–∫—Ä–∏–ø—Ç—É –æ–ø–∏—Å–∞–Ω–∏—è: `/home/lachlan/Projects/image_captioning/clip-gpt-captioning/src/image2caption.py`

–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ `v2c.py`, –µ—Å–ª–∏ —Ç–æ–ª—å–∫–æ –≤—ã –Ω–∞–º–µ—Ä–µ–Ω–Ω–æ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç–µ —ç—Ç–∏ –ø—É—Ç–∏.

### 6. Legacy-–≤–∞—Ä–∏–∞–Ω—Ç (`video2caption_v1.1.py`)

–≠—Ç–æ—Ç —Å–∫—Ä–∏–ø—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –¥–ª—è –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–æ–π —Å–ø—Ä–∞–≤–∫–∏. –î–ª—è –∞–∫—Ç–∏–≤–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø—Ä–µ–¥–ø–æ—á–∏—Ç–∞–π—Ç–µ `v2c.py`.

### 7. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞

```bash
python dataset_generation.py
```

–û–∂–∏–¥–∞–µ–º—ã–µ —Å—ã—Ä—ã–µ –≤—Ö–æ–¥—ã:

- `data/raw/results.csv` (—Ç–∞–±–ª–∏—Ü–∞ –ø–æ–¥–ø–∏—Å–µ–π —Å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–º `|`).
- `data/raw/flickr30k_images/` (—Ñ–∞–π–ª—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, –Ω–∞ –∫–æ—Ç–æ—Ä—ã–µ —Å—Å—ã–ª–∞–µ—Ç—Å—è CSV).

–í—ã—Ö–æ–¥:

- `data/processed/dataset.pkl`

### 8. –û–±—É—á–µ–Ω–∏–µ

```bash
python training.py -S L -C model.pt
```

–û–±—É—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ Weights & Biases (`wandb`).

### 9. –û—Ü–µ–Ω–∫–∞

```bash
python evaluate.py \
  -I ./data/raw/flickr30k_images \
  -R ./data/result/eval \
  -S L \
  -C model.pt \
  -T 1.0
```

–û—Ü–µ–Ω–∫–∞ —Ä–µ–Ω–¥–µ—Ä–∏—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –ø–æ–¥–ø–∏—Å–∏ –ø–æ–≤–µ—Ä—Ö —Ç–µ—Å—Ç–æ–≤—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –∏—Ö –≤:

- `<res-path>/<checkpoint_name_without_ext>_<SIZE>/`

## ‚öôÔ∏è –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã –≤ `utils/config.py`:

| Config | CLIP backbone | GPT model | Weights dir |
|---|---|---|---|
| `ConfigS` | `openai/clip-vit-base-patch32` | `gpt2` | `weights/small` |
| `ConfigL` | `openai/clip-vit-large-patch14` | `gpt2-medium` | `weights/large` |

–ö–ª—é—á–µ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏–∑ –∫–ª–∞—Å—Å–æ–≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏:

| Field | `ConfigS` | `ConfigL` |
|---|---:|---:|
| `epochs` | 150 | 120 |
| `lr` | 3e-3 | 5e-3 |
| `batch_size_exp` | 6 | 5 |
| `ep_len` | 4 | 4 |
| `max_len` | 40 | 40 |

ID –¥–ª—è –∞–≤—Ç–æ-–∑–∞–≥—Ä—É–∑–∫–∏ checkpoint-—Ñ–∞–π–ª–æ–≤ –Ω–∞—Ö–æ–¥—è—Ç—Å—è –≤ `utils/downloads.py`:

| Size | Google Drive ID |
|---|---|
| `L` | `1Gh32arzhW06C1ZJyzcJSSfdJDi3RgWoG` |
| `S` | `1pSQruQyg8KJq6VmzhMLFbT_VaHJMdlWF` |

## üì¶ –í—ã—Ö–æ–¥–Ω—ã–µ —Ñ–∞–π–ª—ã

### –ò–Ω—Ñ–µ—Ä–µ–Ω—Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è

- –°–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –Ω–∞–ª–æ–∂–µ–Ω–Ω—ã–º/—Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –∑–∞–≥–æ–ª–æ–≤–∫–æ–º –≤ `--res-path`.
- –®–∞–±–ª–æ–Ω –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞: `<input_stem>-R<SIZE>.jpg`.

### –ò–Ω—Ñ–µ—Ä–µ–Ω—Å –≤–∏–¥–µ–æ (`v2c.py`)

- SRT: `<video_stem>_caption.srt`
- JSON: `<video_stem>_caption.json`
- –ö–∞–¥—Ä—ã: `<video_stem>_captioning_frames/`

–ü—Ä–∏–º–µ—Ä —ç–ª–µ–º–µ–Ω—Ç–∞ JSON:

```json
{
  "start": "00:00:03,200",
  "end": "00:00:03,700",
  "lang": "en",
  "text": "A dog running through a field."
}
```

## üß™ –ü—Ä–∏–º–µ—Ä—ã

### –ë—ã—Å—Ç—Ä—ã–π –ø—Ä–∏–º–µ—Ä –æ–ø–∏—Å–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è

```bash
python image2caption.py -I ./examples/dog.jpg -S S -C model.pt
```

–û–∂–∏–¥–∞–µ–º–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ:

- –ï—Å–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç `weights/small/model.pt`, —Ñ–∞–π–ª –±—É–¥–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω.
- –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –ø–æ–¥–ø–∏—Å—å—é –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç—Å—è –≤ `./data/result/prediction`.
- –¢–µ–∫—Å—Ç –ø–æ–¥–ø–∏—Å–∏ –≤—ã–≤–æ–¥–∏—Ç—Å—è –≤ stdout.

### –ë—ã—Å—Ç—Ä—ã–π –ø—Ä–∏–º–µ—Ä –æ–ø–∏—Å–∞–Ω–∏—è –≤–∏–¥–µ–æ

```bash
python v2c.py -V ./examples/demo.mp4 -N 8
```

–û–∂–∏–¥–∞–µ–º–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ:

- –ë—É–¥—É—Ç –æ–ø–∏—Å–∞–Ω—ã 8 —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –∫–∞–¥—Ä–æ–≤.
- –§–∞–π–ª—ã `.srt` –∏ `.json` –±—É–¥—É—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã —Ä—è–¥–æ–º —Å –≤—Ö–æ–¥–Ω—ã–º –≤–∏–¥–µ–æ.

### –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è/–æ—Ü–µ–Ω–∫–∏ end-to-end

```bash
python dataset_generation.py
python training.py -S L -C model.pt
python evaluate.py -I ./data/raw/flickr30k_images -R ./data/result/eval -S L -C model.pt -T 1.0
```

## üß≠ –ó–∞–º–µ—Ç–∫–∏ –ø–æ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ

- –í `v2c.py`, `video2caption.py` –∏ `video2caption_v1.*` –µ—Å—Ç—å –ø–µ—Ä–µ—Å–µ–∫–∞—é—â–∏–π—Å—è legacy-—Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª.
- `video2caption_v1.0_not_work.py` –Ω–∞–º–µ—Ä–µ–Ω–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –∫–∞–∫ –Ω–µ—Ä–∞–±–æ—Ç–∞—é—â–∏–π legacy-–∫–æ–¥.
- `training.py` —Å–µ–π—á–∞—Å –≤—ã–±–∏—Ä–∞–µ—Ç `ConfigL()` —á–µ—Ä–µ–∑ `config = ConfigL() if args.size.upper() else ConfigS()`, —á—Ç–æ –≤—Å–µ–≥–¥–∞ –ø—Ä–∏–≤–æ–¥–∏—Ç –∫ `ConfigL` –ø—Ä–∏ –Ω–µ–ø—É—Å—Ç–æ–º –∑–Ω–∞—á–µ–Ω–∏–∏ `--size`.
- `model/trainer.py` –∏—Å–ø–æ–ª—å–∑—É–µ—Ç `self.dataset` –≤ `test_step`, —Ç–æ–≥–¥–∞ –∫–∞–∫ –≤ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ç–æ—Ä–µ –ø—Ä–∏—Å–≤–∞–∏–≤–∞–µ—Ç—Å—è `self.test_dataset`; —ç—Ç–æ –º–æ–∂–µ—Ç –ª–æ–º–∞—Ç—å –≤—ã–±–æ—Ä–∫—É –≤ –æ–±—É—á–∞—é—â–∏—Ö –∑–∞–ø—É—Å–∫–∞—Ö –±–µ–∑ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è.
- `video2caption_v1.1.py` —Å—Å—ã–ª–∞–µ—Ç—Å—è –Ω–∞ `self.config.transform`, –Ω–æ –≤ `ConfigS`/`ConfigL` –ø–æ–ª–µ `transform` –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ.
- –í —Ç–µ–∫—É—â–µ–º —Å–Ω–∏–º–∫–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è –Ω–µ—Ç CI/–Ω–∞–±–æ—Ä–∞ —Ç–µ—Å—Ç–æ–≤.
- –ü—Ä–∏–º–µ—á–∞–Ω–∏–µ –ø–æ i18n: —è–∑—ã–∫–æ–≤—ã–µ —Å—Å—ã–ª–∫–∏ –µ—Å—Ç—å –≤–≤–µ—Ä—Ö—É —ç—Ç–æ–≥–æ README; –ø–µ—Ä–µ–≤–æ–¥–Ω—ã–µ —Ñ–∞–π–ª—ã –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–ª—è—Ç—å –≤ `i18n/`.
- –ü—Ä–∏–º–µ—á–∞–Ω–∏–µ –æ —Ç–µ–∫—É—â–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏: —è–∑—ã–∫–æ–≤–∞—è —Å—Ç—Ä–æ–∫–∞ —Å—Å—ã–ª–∞–µ—Ç—Å—è –Ω–∞ `i18n/README.ru.md`, –Ω–æ –≤ —ç—Ç–æ–º —Å–Ω–∏–º–∫–µ —ç—Ç–æ—Ç —Ñ–∞–π–ª –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç.

## ü©∫ –£—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –Ω–µ–ø–æ–ª–∞–¥–æ–∫

- `AssertionError: Image does not exist`
  - –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ `-I/--img-path` —É–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —Ñ–∞–π–ª.
- `Dataset file not found. Downloading...`
  - `MiniFlickrDataset` –≤—ã–±—Ä–∞—Å—ã–≤–∞–µ—Ç —ç—Ç–æ —Å–æ–æ–±—â–µ–Ω–∏–µ, –∫–æ–≥–¥–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç `data/processed/dataset.pkl`; —Å–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ `python dataset_generation.py`.
- `Path to the test image folder does not exist`
  - –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ `evaluate.py -I` —É–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –ø–∞–ø–∫—É.
- –ú–µ–¥–ª–µ–Ω–Ω—ã–π –∏–ª–∏ –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω—ã–π –ø–µ—Ä–≤—ã–π –∑–∞–ø—É—Å–∫
  - –ü—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—É—Å–∫–µ –∑–∞–≥—Ä—É–∂–∞—é—Ç—Å—è –º–æ–¥–µ–ª–∏ Hugging Face –∏ –º–æ–∂–µ—Ç –≤—ã–ø–æ–ª–Ω—è—Ç—å—Å—è –∑–∞–≥—Ä—É–∑–∫–∞ checkpoint-—Ñ–∞–π–ª–æ–≤ –∏–∑ Google Drive.
- `video2caption.py` –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Å—Ç—ã–µ –ø–æ–¥–ø–∏—Å–∏
  - –ü—Ä–æ–≤–µ—Ä—å—Ç–µ hardcoded –ø—É—Ç—å –∫ —Å–∫—Ä–∏–ø—Ç—É –∏ Python executable, –ª–∏–±–æ –ø–µ—Ä–µ–∫–ª—é—á–∏—Ç–µ—Å—å –Ω–∞ `v2c.py`.
- –í–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è `wandb` –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ—Ç –≤—Ö–æ–¥
  - –í—ã–ø–æ–ª–Ω–∏—Ç–µ `wandb login` –∏–ª–∏ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –≤—Ä—É—á–Ω—É—é –æ—Ç–∫–ª—é—á–∏—Ç–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ `training.py`.

## üõ£Ô∏è –î–æ—Ä–æ–∂–Ω–∞—è –∫–∞—Ä—Ç–∞

- –î–æ–±–∞–≤–∏—Ç—å lockfile –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π (`requirements.txt` –∏–ª–∏ `pyproject.toml`) –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ–π —É—Å—Ç–∞–Ω–æ–≤–∫–∏.
- –û–±—ä–µ–¥–∏–Ω–∏—Ç—å –¥—É–±–ª–∏—Ä—É—é—â–∏–µ—Å—è video-–ø–∞–π–ø–ª–∞–π–Ω—ã –≤ –æ–¥–Ω—É –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—É—é —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—é.
- –£–±—Ä–∞—Ç—å hardcoded machine paths –∏–∑ legacy-—Å–∫—Ä–∏–ø—Ç–æ–≤.
- –ò—Å–ø—Ä–∞–≤–∏—Ç—å –∏–∑–≤–µ—Å—Ç–Ω—ã–µ edge-case –±–∞–≥–∏ –æ–±—É—á–µ–Ω–∏—è/–æ—Ü–µ–Ω–∫–∏ –≤ `training.py` –∏ `model/trainer.py`.
- –î–æ–±–∞–≤–∏—Ç—å –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã –∏ CI.
- –ó–∞–ø–æ–ª–Ω–∏—Ç—å `i18n/` –ø–µ—Ä–µ–≤–æ–¥–∞–º–∏ README, –Ω–∞ –∫–æ—Ç–æ—Ä—ã–µ —Å—Å—ã–ª–∞–µ—Ç—Å—è —è–∑—ã–∫–æ–≤–∞—è —Å—Ç—Ä–æ–∫–∞.

## ü§ù –í–∫–ª–∞–¥

–í–∫–ª–∞–¥—ã –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤—É—é—Ç—Å—è. –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π —Ä–∞–±–æ—á–∏–π –ø—Ä–æ—Ü–µ—Å—Å:

```bash
# 1) Fork and clone
git clone git@github.com:<your-user>/VideoCaptionerWithClip.git
cd VideoCaptionerWithClip

# 2) Create a feature branch
git checkout -b feat/your-change

# 3) Make changes and commit
git add .
git commit -m "feat: describe your change"

# 4) Push and open a PR
git push origin feat/your-change
```

–ï—Å–ª–∏ –≤—ã –º–µ–Ω—è–µ—Ç–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏, –¥–æ–±–∞–≤—å—Ç–µ:

- –í–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º—É—é(—ã–µ) –∫–æ–º–∞–Ω–¥—É(—ã).
- –ü—Ä–∏–º–µ—Ä—ã —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–æ/–ø–æ—Å–ª–µ.
- –ü—Ä–∏–º–µ—á–∞–Ω–∏—è –æ –ø—Ä–µ–¥–ø–æ–ª–æ–∂–µ–Ω–∏—è—Ö –ø–æ checkpoint-—Ñ–∞–π–ª–∞–º –∏–ª–∏ –¥–∞—Ç–∞—Å–µ—Ç—É.

## üôå –ü–æ–¥–¥–µ—Ä–∂–∫–∞

–í —Ç–µ–∫—É—â–µ–º —Å–Ω–∏–º–∫–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è –Ω–µ—Ç —è–≤–Ω–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–æ–Ω–∞—Ç–æ–≤/—Å–ø–æ–Ω—Å–æ—Ä—Å—Ç–≤–∞.

–ï—Å–ª–∏ —Å—Å—ã–ª–∫–∏ –Ω–∞ —Å–ø–æ–Ω—Å–æ—Ä—Å—Ç–≤–æ –±—É–¥—É—Ç –¥–æ–±–∞–≤–ª–µ–Ω—ã –ø–æ–∑–∂–µ, –∏—Ö —Å–ª–µ–¥—É–µ—Ç —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ —ç—Ç–æ–º —Ä–∞–∑–¥–µ–ª–µ.

## üìÑ –õ–∏—Ü–µ–Ω–∑–∏—è

–í —Ç–µ–∫—É—â–µ–º —Å–Ω–∏–º–∫–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç —Ñ–∞–π–ª –ª–∏—Ü–µ–Ω–∑–∏–∏.

–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ-–ø—Ä–µ–¥–ø–æ–ª–æ–∂–µ–Ω–∏–µ: –ø–æ–∫–∞ –Ω–µ –¥–æ–±–∞–≤–ª–µ–Ω —Ñ–∞–π–ª `LICENSE`, —É—Å–ª–æ–≤–∏—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è/—Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã.

[English](../README.md) Â· [Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©](README.ar.md) Â· [EspaÃ±ol](README.es.md) Â· [FranÃ§ais](README.fr.md) Â· [æ—¥æœ¬èª](README.ja.md) Â· [í•œêµ­ì–´](README.ko.md) Â· [Tiáº¿ng Viá»‡t](README.vi.md) Â· [ä¸­æ–‡ (ç®€ä½“)](README.zh-Hans.md) Â· [ä¸­æ–‡ï¼ˆç¹é«”ï¼‰](README.zh-Hant.md) Â· [Deutsch](README.de.md) Â· [Ğ ÑƒÑÑĞºĞ¸Ğ¹](README.ru.md)



[![LazyingArt banner](https://github.com/lachlanchen/lachlanchen/raw/main/figs/banner.png)](https://github.com/lachlanchen/lachlanchen/blob/main/figs/banner.png)


# Clip-GPT-Captioning

![Python](https://img.shields.io/badge/Python-3.10%2B-blue)
![PyTorch](https://img.shields.io/badge/PyTorch-2.x-red)
![Transformers](https://img.shields.io/badge/HuggingFace-Transformers-yellow)
![Status](https://img.shields.io/badge/README-Expanded-success)
![Repo Layout](https://img.shields.io/badge/Layout-Root%20Scripts-informational)
![Legacy Scripts](https://img.shields.io/badge/Legacy%20Scripts-Present-orange)
![i18n](https://img.shields.io/badge/i18n-Enabled-brightgreen)
![Maintained Path](https://img.shields.io/badge/Video-v2c.py-2ea44f)
![Contributions](https://img.shields.io/badge/Contributions-Welcome-2ea44f?style=flat-square)
![Issues](https://img.shields.io/github/issues-raw/lachlanchen/VideoCaptionerWithClip?style=flat-square)
![Last Commit](https://img.shields.io/github/last-commit/lachlanchen/VideoCaptionerWithClip?style=flat-square)

---

## ğŸ§­ Quick Navigation

| Má»¥c | DÃ¹ng Ä‘á»ƒ |
|---|---|
| Snapshot | Xem pháº¡m vi repo vÃ  danh má»¥c script hiá»‡n táº¡i |
| Overview | Äá»c má»¥c tiÃªu vÃ  pháº¡m vi nÄƒng lá»±c |
| Usage | Thá»±c hiá»‡n Ä‘Ãºng cÃ¡c quy trÃ¬nh CLI/API |
| Troubleshooting | Kháº¯c phá»¥c nhanh cÃ¡c lá»—i cháº¡y thÆ°á»ng gáº·p |
| Roadmap | Theo dÃµi cÃ¡c má»¥c tá»‘i Æ°u/sá»­a lá»—i Ä‘Ã£ biáº¿t |

---

Bá»™ cÃ´ng cá»¥ Python sinh mÃ´ táº£ ngÃ´n ngá»¯ tá»± nhiÃªn cho áº£nh vÃ  video báº±ng cÃ¡ch káº¿t há»£p embedding hÃ¬nh áº£nh tá»« OpenAI CLIP vá»›i mÃ´ hÃ¬nh ngÃ´n ngá»¯ kiá»ƒu GPT.

## ğŸ§­ Snapshot

| Pháº¡m vi | Chi tiáº¿t |
|---|---|
| Pháº¡m vi tÃ¡c vá»¥ | Sinh caption cho áº£nh vÃ  video |
| Káº¿t quáº£ chÃ­nh | Subtitle SRT, transcript JSON, áº£nh Ä‘Ã£ gáº¯n caption |
| Script chÃ­nh | `i2c.py`, `v2c.py`, `image2caption.py` |
| ÄÆ°á»ng Ä‘i legacy | `video2caption.py` vÃ  cÃ¡c phiÃªn báº£n liÃªn quan (giá»¯ Ä‘á»ƒ tham chiáº¿u lá»‹ch sá»­) |
| Luá»“ng dá»¯ liá»‡u | `data/raw/results.csv` + `data/raw/flickr30k_images/` |

## âœ¨ Tá»•ng quan

Repo nÃ y cung cáº¥p:

- Script suy luáº­n cho caption áº£nh vÃ  sinh phá»¥ Ä‘á» video.
- Pipeline huáº¥n luyá»‡n Ã¡nh xáº¡ embedding áº£nh CLIP sang embedding token cá»§a GPT-2.
- Tiá»‡n Ã­ch táº¡o bá»™ dá»¯ liá»‡u theo phong cÃ¡ch Flickr30k.
- Tá»± Ä‘á»™ng táº£i checkpoint theo kÃ­ch thÆ°á»›c mÃ´ hÃ¬nh khi thiáº¿u file trá»ng sá»‘.
- CÃ¡c báº£n README Ä‘a ngÃ´n ngá»¯ trong `i18n/` (xem thanh ngÃ´n ngá»¯ phÃ­a trÃªn).

Triá»ƒn khai hiá»‡n táº¡i cÃ³ cáº£ script má»›i vÃ  script káº¿ thá»«a. Má»™t sá»‘ file cÅ© Ä‘Æ°á»£c giá»¯ láº¡i Ä‘á»ƒ tham kháº£o vÃ  Ä‘Æ°á»£c mÃ´ táº£ bÃªn dÆ°á»›i.

## ğŸš€ TÃ­nh nÄƒng

- Sinh caption cho áº£nh Ä‘Æ¡n qua `image2caption.py`.
- Sinh caption video (láº¥y máº«u frame Ä‘á»u nhau) qua `v2c.py` hoáº·c `video2caption.py`.
- TÃ¹y chá»‰nh thá»i gian cháº¡y:
  - Sá»‘ frame.
  - KÃ­ch thÆ°á»›c mÃ´ hÃ¬nh.
  - Nhiá»‡t Ä‘á»™ láº¥y máº«u.
  - TÃªn checkpoint.
- Song song/multi-process Ä‘á»ƒ suy luáº­n video nhanh hÆ¡n.
- Äáº§u ra:
  - File subtitle SRT (`.srt`).
  - Transcript JSON (`.json`) trong `v2c.py`.
- Äiá»ƒm khá»Ÿi Ä‘áº§u huáº¥n luyá»‡n vÃ  Ä‘Ã¡nh giÃ¡ cho thá»­ nghiá»‡m Ã¡nh xáº¡ CLIP+GPT2.

### TÃ³m táº¯t nhanh

| Khu vá»±c | Script chÃ­nh | Ghi chÃº |
|---|---|---|
| Caption áº£nh | `image2caption.py`, `i2c.py`, `predict.py` | CÃ³ cáº£ CLI vÃ  class cÃ³ thá»ƒ tÃ¡i sá»­ dá»¥ng |
| Caption video | `v2c.py` | ÄÆ°á»ng dáº«n Ä‘ang Ä‘Æ°á»£c duy trÃ¬ khuyáº¿n nghá»‹ |
| Luá»“ng káº¿ thá»«a video | `video2caption.py`, `video2caption_v1.1.py` | Chá»©a giáº£ Ä‘á»‹nh riÃªng cho mÃ¡y cá»¥ thá»ƒ |
| Táº¡o dataset | `dataset_generation.py` | Táº¡o `data/processed/dataset.pkl` |
| Train / eval | `training.py`, `evaluate.py` | DÃ¹ng Ã¡nh xáº¡ CLIP+GPT2 |

## ğŸ§± Kiáº¿n trÃºc (Tá»•ng quan)

MÃ´ hÃ¬nh lÃµi trong `model/model.py` gá»“m ba pháº§n:

1. `ImageEncoder`: trÃ­ch xuáº¥t embedding áº£nh tá»« CLIP.
2. `Mapping`: chiáº¿u embedding CLIP thÃ nh dÃ£y embedding tiá»n tá»‘ cho GPT.
3. `TextDecoder`: head mÃ´ hÃ¬nh GPT-2 sinh token caption theo autoregressive.

Huáº¥n luyá»‡n (`Net.train_forward`) dÃ¹ng trÆ°á»›c embedding áº£nh CLIP Ä‘Ã£ tiá»n xá»­ lÃ½ + caption Ä‘Ã£ tokenize.
Suy luáº­n (`Net.forward`) nháº­n áº£nh PIL vÃ  giáº£i mÃ£ token Ä‘áº¿n khi gáº·p EOS hoáº·c `max_len`.

### Luá»“ng dá»¯ liá»‡u

1. Chuáº©n bá»‹ dataset: `dataset_generation.py` Ä‘á»c `data/raw/results.csv` vÃ  áº£nh trong `data/raw/flickr30k_images/`, ghi ra `data/processed/dataset.pkl`.
2. Huáº¥n luyá»‡n: `training.py` Ä‘á»c tuple pickle `(image_name, image_embedding, caption)` vÃ  huáº¥n luyá»‡n cÃ¡c lá»›p mapper/decoder.
3. ÄÃ¡nh giÃ¡: `evaluate.py` render caption sinh ra lÃªn táº­p áº£nh test.
4. Thá»±c thi suy luáº­n:
   - áº£nh: `image2caption.py` / `predict.py` / `i2c.py`.
   - video: `v2c.py` (khuyáº¿n nghá»‹), `video2caption.py` (legacy).

## ğŸ—‚ï¸ Cáº¥u trÃºc dá»± Ã¡n

```text
VideoCaptionerWithClip/
â”œâ”€â”€ README.md
â”œâ”€â”€ image2caption.py               # Single-image caption CLI
â”œâ”€â”€ predict.py                     # Alternate single-image caption CLI
â”œâ”€â”€ i2c.py                         # Reusable ImageCaptioner class + CLI
â”œâ”€â”€ v2c.py                         # Video -> SRT + JSON (threaded frame captioning)
â”œâ”€â”€ video2caption.py               # Alternate video -> SRT implementation (legacy constraints)
â”œâ”€â”€ video2caption_v1.1.py          # Older variant
â”œâ”€â”€ video2caption_v1.0_not_work.py # Explicitly marked non-working legacy file
â”œâ”€â”€ training.py                    # Model training entrypoint
â”œâ”€â”€ evaluate.py                    # Test-split evaluation and rendered outputs
â”œâ”€â”€ dataset_generation.py          # Builds data/processed/dataset.pkl
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ dataset.py                 # Dataset + DataLoader helpers
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ model.py                   # CLIP encoder + mapping + GPT2 decoder
â”‚   â””â”€â”€ trainer.py                 # Training/validation/test utility class
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                  # ConfigS / ConfigL defaults
â”‚   â”œâ”€â”€ downloads.py               # Google Drive checkpoint downloader
â”‚   â””â”€â”€ lr_warmup.py               # LR warmup schedule
â”œâ”€â”€ i18n/                          # Multilingual README variants
â””â”€â”€ .auto-readme-work/             # Auto-README pipeline artifacts
```

## ğŸ“‹ YÃªu cáº§u

- Khuyáº¿n nghá»‹ dÃ¹ng Python `3.10+`.
- GPU cÃ³ há»— trá»£ CUDA lÃ  khÃ´ng báº¯t buá»™c nhÆ°ng ráº¥t khuyáº¿n nghá»‹ cho huáº¥n luyá»‡n vÃ  suy luáº­n mÃ´ hÃ¬nh lá»›n.
- `ffmpeg` khÃ´ng báº¯t buá»™c trá»±c tiáº¿p cho cÃ¡c script hiá»‡n táº¡i (OpenCV Ä‘Æ°á»£c dÃ¹ng Ä‘á»ƒ trÃ­ch frame).
- Cáº§n cÃ³ truy cáº­p Internet cho láº§n táº£i Ä‘áº§u tiÃªn mÃ´ hÃ¬nh/checkpoint tá»« Hugging Face hoáº·c Google Drive.

Hiá»‡n chÆ°a cÃ³ lockfile (`requirements.txt` / `pyproject.toml` chÆ°a cÃ³), nÃªn phá»¥ thuá»™c Ä‘Æ°á»£c suy ra tá»« import trong mÃ£ nguá»“n.

## ğŸ› ï¸ CÃ i Ä‘áº·t

### CÃ i Ä‘áº·t chuáº©n theo cáº¥u trÃºc repo hiá»‡n táº¡i

```bash
git clone git@github.com:lachlanchen/VideoCaptionerWithClip.git
cd VideoCaptionerWithClip

python -m venv .venv
source .venv/bin/activate

pip install --upgrade pip
pip install torch torchvision torchaudio
pip install transformers pillow matplotlib numpy tqdm opencv-python pandas wandb gdown
```

### Snippet cÃ i Ä‘áº·t tá»« README cÅ© (Ä‘Æ°á»£c giá»¯ nguyÃªn)

README trÆ°á»›c káº¿t thÃºc giá»¯a khá»‘i lá»‡nh. CÃ¡c lá»‡nh gá»‘c Ä‘Æ°á»£c giá»¯ Ä‘Ãºng nhÆ° nguá»“n lá»‹ch sá»­ bÃªn dÆ°á»›i:

```bash
git clone git@github.com:lachlanchen/VideoCaptionerWithClip.git
cd VideoCaptionerWithClip/src
```

LÆ°u Ã½: snapshot hiá»‡n táº¡i Ä‘áº·t táº¥t cáº£ script á»Ÿ root repo, khÃ´ng náº±m trong `src/`.

## â–¶ï¸ Báº¯t Ä‘áº§u nhanh

| Má»¥c tiÃªu | Lá»‡nh |
|---|---|
| Caption má»™t áº£nh | `python image2caption.py -I /path/to/image.jpg -S L -C model.pt` |
| Caption má»™t video | `python v2c.py -V /path/to/video.mp4 -N 10` |
| Táº¡o dataset | `python dataset_generation.py` |

### Caption áº£nh (cháº¡y nhanh)

```bash
python image2caption.py -I /path/to/image.jpg -S L -C model.pt
```

### Caption video (Ä‘Æ°á»ng dáº«n khuyáº¿n nghá»‹)

```bash
python v2c.py -V /path/to/video.mp4 -N 10
```

## ğŸ¯ HÆ°á»›ng dáº«n sá»­ dá»¥ng

### 1. Caption áº£nh (`image2caption.py`)

```bash
python image2caption.py \
  -I /path/to/image.jpg \
  -S L \
  -C model.pt \
  -R ./data/result/prediction \
  -T 1.0
```

Äá»‘i sá»‘:

- `-I, --img-path`: Ä‘Æ°á»ng dáº«n áº£nh Ä‘áº§u vÃ o.
- `-S, --size`: kÃ­ch thÆ°á»›c mÃ´ hÃ¬nh (`S` hoáº·c `L`).
- `-C, --checkpoint-name`: tÃªn file checkpoint trong `weights/{small|large}`.
- `-R, --res-path`: thÆ° má»¥c output cho áº£nh Ä‘Ã£ render caption.
- `-T, --temperature`: tham sá»‘ nhiá»‡t Ä‘á»™ sampling.

### 2. CLI áº£nh thay tháº¿ (`predict.py`)

```bash
python predict.py \
  -I /path/to/image.jpg \
  -S L \
  -C model.pt \
  -R ./data/result/prediction \
  -T 1.0
```

`predict.py` hoáº¡t Ä‘á»™ng tÆ°Æ¡ng tá»± `image2caption.py`; chá»‰ khÃ¡c má»™t chÃºt pháº§n format Ä‘áº§u ra.

### 3. API class caption áº£nh (`i2c.py`)

```bash
python i2c.py -I /path/to/image.jpg -S L -C model.pt -R ./data/result/prediction -T 1.0
```

Hoáº·c import trong script riÃªng:

```python
from i2c import ImageCaptioner

captioner = ImageCaptioner(model_size="L", checkpoint_name="model.pt")
captioner.set_image_path("/path/to/image.jpg")
caption = captioner.generate_caption(save_image=True)
print(caption)
```

### 4. Caption video thÃ nh subtitle + JSON (`v2c.py`)

```bash
python v2c.py -V /path/to/video.mp4 -N 10
```

Káº¿t quáº£ xuáº¥t ra cáº¡nh file video gá»‘c:

- `<video_basename>_caption.srt`
- `<video_basename>_caption.json`
- `<video_basename>_captioning_frames/`

### 5. Pipeline thay tháº¿ (`video2caption.py`)

```bash
python video2caption.py -V /path/to/video.mp4 -N 10
```

LÆ°u Ã½ quan trá»ng: script nÃ y hiá»‡n cÃ²n chá»©a má»™t sá»‘ Ä‘Æ°á»ng dáº«n cá»©ng theo mÃ¡y cá»¥ thá»ƒ:

- Python máº·c Ä‘á»‹nh: `/home/lachlan/miniconda3/envs/caption/bin/python`
- ÄÆ°á»ng dáº«n caption script: `/home/lachlan/Projects/image_captioning/clip-gpt-captioning/src/image2caption.py`

NÃªn dÃ¹ng `v2c.py` náº¿u báº¡n khÃ´ng cÃ³ nhu cáº§u duy trÃ¬ cá»‘ Ä‘á»‹nh cÃ¡c Ä‘Æ°á»ng dáº«n trÃªn.

### 6. PhiÃªn báº£n legacy (`video2caption_v1.1.py`)

Script nÃ y Ä‘Æ°á»£c giá»¯ láº¡i Ä‘á»ƒ tham chiáº¿u lá»‹ch sá»­. Vá»›i sá»­ dá»¥ng háº±ng ngÃ y nÃªn chá»n `v2c.py`.

### 7. Táº¡o dataset

```bash
python dataset_generation.py
```

Äáº§u vÃ o thÃ´ mong Ä‘á»£i:

- `data/raw/results.csv` (báº£ng caption phÃ¢n tÃ¡ch báº±ng pipe).
- `data/raw/flickr30k_images/` (cÃ¡c file áº£nh Ä‘Æ°á»£c tham chiáº¿u trong CSV).

Äáº§u ra:

- `data/processed/dataset.pkl`

### 8. Huáº¥n luyá»‡n

```bash
python training.py -S L -C model.pt
```

Huáº¥n luyá»‡n máº·c Ä‘á»‹nh log báº±ng Weights & Biases (`wandb`).

### 9. ÄÃ¡nh giÃ¡

```bash
python evaluate.py \
  -I ./data/raw/flickr30k_images \
  -R ./data/result/eval \
  -S L \
  -C model.pt \
  -T 1.0
```

Káº¿t quáº£ Ä‘Ã¡nh giÃ¡ render caption lÃªn áº£nh test vÃ  lÆ°u táº¡i:

- `<res-path>/<checkpoint_name_without_ext>_<SIZE>/`

## âš™ï¸ Cáº¥u hÃ¬nh

CÃ¡c cáº¥u hÃ¬nh mÃ´ hÃ¬nh náº±m trong `utils/config.py`:

| Cáº¥u hÃ¬nh | CLIP backbone | MÃ´ hÃ¬nh GPT | ThÆ° má»¥c weights |
|---|---|---|---|
| `ConfigS` | `openai/clip-vit-base-patch32` | `gpt2` | `weights/small` |
| `ConfigL` | `openai/clip-vit-large-patch14` | `gpt2-medium` | `weights/large` |

CÃ¡c tham sá»‘ máº·c Ä‘á»‹nh:

| TrÆ°á»ng | `ConfigS` | `ConfigL` |
|---|---:|---:|
| `epochs` | 150 | 120 |
| `lr` | 3e-3 | 5e-3 |
| `batch_size_exp` | 6 | 5 |
| `ep_len` | 4 | 4 |
| `max_len` | 40 | 40 |

ID checkpoint tá»± Ä‘á»™ng táº£i Ä‘Æ°á»£c lÆ°u trong `utils/downloads.py`:

| KÃ­ch thÆ°á»›c | Google Drive ID |
|---|---|
| `L` | `1Gh32arzhW06C1ZJyzcJSSfdJDi3RgWoG` |
| `S` | `1pSQruQyg8KJq6VmzhMLFbT_VaHJMdlWF` |

## ğŸ“¦ File Ä‘áº§u ra

### Suy luáº­n áº£nh

- áº¢nh káº¿t quáº£ vá»›i chá»¯ caption overlay Ä‘Æ°á»£c lÆ°u táº¡i `--res-path`.
- Máº«u tÃªn file: `<input_stem>-R<SIZE>.jpg`.

### Suy luáº­n video (`v2c.py`)

- SRT: `<video_stem>_caption.srt`
- JSON: `<video_stem>_caption.json`
- áº¢nh frame: `<video_stem>_captioning_frames/`

VÃ­ dá»¥ pháº§n tá»­ JSON:

```json
{
  "start": "00:00:03,200",
  "end": "00:00:03,700",
  "lang": "en",
  "text": "A dog running through a field."
}
```

## ğŸ§ª VÃ­ dá»¥

### VÃ­ dá»¥ caption áº£nh nhanh

```bash
python image2caption.py -I ./examples/dog.jpg -S S -C model.pt
```

HÃ nh vi mong Ä‘á»£i:

- Náº¿u `weights/small/model.pt` chÆ°a cÃ³, nÃ³ sáº½ tá»± táº£i.
- Máº·c Ä‘á»‹nh sáº½ táº¡o áº£nh cÃ³ caption trong `./data/result/prediction`.
- Text caption Ä‘Æ°á»£c in ra stdout.

### VÃ­ dá»¥ caption video nhanh

```bash
python v2c.py -V ./examples/demo.mp4 -N 8
```

HÃ nh vi mong Ä‘á»£i:

- 8 frame Ä‘Æ°á»£c láº¥y máº«u Ä‘á»u vÃ  Ä‘Æ°á»£c caption.
- File `.srt` vÃ  `.json` sáº½ sinh cáº¡nh video Ä‘áº§u vÃ o.

### Chuá»—i huáº¥n luyá»‡n + Ä‘Ã¡nh giÃ¡ end-to-end

```bash
python dataset_generation.py
python training.py -S L -C model.pt
python evaluate.py -I ./data/raw/flickr30k_images -R ./data/result/eval -S L -C model.pt -T 1.0
```

## ğŸ§­ Ghi chÃº phÃ¡t triá»ƒn

- `v2c.py`, `video2caption.py`, vÃ  `video2caption_v1.*` cÃ³ pháº§n chá»©c nÄƒng láº·p láº¡i.
- `video2caption_v1.0_not_work.py` Ä‘Æ°á»£c giá»¯ cÃ³ chá»§ Ä‘Ã­ch nhÆ° legacy khÃ´ng cÃ²n dÃ¹ng.
- `training.py` hiá»‡n Ä‘ang chá»n `ConfigL()` qua `config = ConfigL() if args.size.upper() else ConfigS()`, nÃªn gáº§n nhÆ° luÃ´n tráº£ vá» `ConfigL` khi `--size` khÃ´ng rá»—ng.
- `model/trainer.py` dÃ¹ng `self.dataset` trong `test_step`, trong khi initializer láº¡i gÃ¡n `self.test_dataset`; Ä‘iá»ƒm nÃ y cÃ³ thá»ƒ lÃ m lá»—i láº¥y máº«u trong má»™t sá»‘ láº§n train náº¿u khÃ´ng chá»‰nh.
- `video2caption_v1.1.py` tham chiáº¿u `self.config.transform`, nhÆ°ng `ConfigS`/`ConfigL` khÃ´ng cÃ³ trÆ°á»ng `transform`.
- Repo hiá»‡n chÆ°a cÃ³ CI/test suite.
- Ghi chÃº i18n: thanh ngÃ´n ngá»¯ náº±m Ä‘áº§u README; cÃ¡c file dá»‹ch cÃ³ thá»ƒ Ä‘Æ°á»£c thÃªm vÃ o `i18n/`.
- Hiá»‡n tráº¡ng: thanh ngÃ´n ngá»¯ cÃ³ liÃªn káº¿t `i18n/README.ru.md`, nhÆ°ng file nÃ y chÆ°a cÃ³ trong snapshot nÃ y.

## ğŸ©º Kháº¯c phá»¥c sá»± cá»‘

- `AssertionError: Image does not exist`
  - Kiá»ƒm tra `-I/--img-path` trá» tá»›i má»™t file há»£p lá»‡.
- `Dataset file not found. Downloading...`
  - `MiniFlickrDataset` phÃ¡t ra lá»—i khi thiáº¿u `data/processed/dataset.pkl`; hÃ£y cháº¡y `python dataset_generation.py` trÆ°á»›c.
- `Path to the test image folder does not exist`
  - Kiá»ƒm tra `evaluate.py -I` trá» Ä‘Ãºng thÆ° má»¥c Ä‘Ã£ tá»“n táº¡i.
- Cháº¡y Ä‘áº§u tiÃªn cháº­m/khÃ´ng á»•n
  - Láº§n Ä‘áº§u cÃ³ thá»ƒ pháº£i táº£i mÃ´ hÃ¬nh tá»« Hugging Face vÃ /hoáº·c checkpoint tá»« Google Drive.
- `video2caption.py` tráº£ vá» caption rá»—ng
  - Kiá»ƒm tra láº¡i Ä‘Æ°á»ng dáº«n hardcode vÃ  Ä‘Æ°á»ng dáº«n python executable, hoáº·c chuyá»ƒn sang `v2c.py`.
- `wandb` yÃªu cáº§u Ä‘Äƒng nháº­p trong quÃ¡ trÃ¬nh train
  - Cháº¡y `wandb login` hoáº·c táº¯t logging thá»§ cÃ´ng trong `training.py` náº¿u cáº§n.

## ğŸ›£ï¸ Lá»™ trÃ¬nh

- ThÃªm lockfile phá»¥ thuá»™c (`requirements.txt` hoáº·c `pyproject.toml`) Ä‘á»ƒ cÃ i Ä‘áº·t tÃ¡i láº­p.
- Gá»™p cÃ¡c pipeline video trÃ¹ng láº·p vá» má»™t báº£n duy nháº¥t Ä‘ang duy trÃ¬.
- Loáº¡i bá» Ä‘Æ°á»ng dáº«n mÃ¡y cá»©ng trong cÃ¡c script legacy.
- Sá»­a lá»—i biÃªn Ä‘Ã£ biáº¿t trong huáº¥n luyá»‡n/Ä‘Ã¡nh giÃ¡ táº¡i `training.py` vÃ  `model/trainer.py`.
- ThÃªm test tá»± Ä‘á»™ng vÃ  CI.
- Bá»• sung Ä‘áº§y Ä‘á»§ README dá»‹ch trong `i18n/` theo Ä‘Ãºng ngÃ´n ngá»¯ trÃªn thanh Ä‘iá»u hÆ°á»›ng.

## ğŸ¤ ÄÃ³ng gÃ³p

Má»i Ä‘Ã³ng gÃ³p Ä‘á»u Ä‘Æ°á»£c chÃ o Ä‘Ã³n. Quy trÃ¬nh gá»£i Ã½:

```bash
# 1) Fork vÃ  clone
git clone git@github.com:<your-user>/VideoCaptionerWithClip.git
cd VideoCaptionerWithClip

# 2) Táº¡o nhÃ¡nh feature
git checkout -b feat/your-change

# 3) Chá»‰nh sá»­a vÃ  commit
git add .
git commit -m "feat: describe your change"

# 4) Push vÃ  má»Ÿ PR
git push origin feat/your-change
```

Náº¿u báº¡n sá»­a Ä‘á»•i hÃ nh vi model, cáº§n kÃ¨m:

- Lá»‡nh reproduce Ä‘Æ°á»£c.
- VÃ­ dá»¥ Ä‘áº§u ra trÆ°á»›c/sau.
- Ghi chÃº vá» giáº£ Ä‘á»‹nh checkpoint hoáº·c dá»¯ liá»‡u.

---

## â¤ï¸ Support

| Donate | PayPal | Stripe |
| --- | --- | --- |
| [![Donate](https://camo.githubusercontent.com/24a4914f0b42c6f435f9e101621f1e52535b02c225764b2f6cc99416926004b7/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f446f6e6174652d4c617a79696e674172742d3045413545393f7374796c653d666f722d7468652d6261646765266c6f676f3d6b6f2d6669266c6f676f436f6c6f723d7768697465)](https://chat.lazying.art/donate) | [![PayPal](https://camo.githubusercontent.com/d0f57e8b016517a4b06961b24d0ca87d62fdba16e18bbdb6aba28e978dc0ea21/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f50617950616c2d526f6e677a686f754368656e2d3030343537433f7374796c653d666f722d7468652d6261646765266c6f676f3d70617970616c266c6f676f436f6c6f723d7768697465)](https://paypal.me/RongzhouChen) | [![Stripe](https://camo.githubusercontent.com/1152dfe04b6943afe3a8d2953676749603fb9f95e24088c92c97a01a897b4942/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f5374726970652d446f6e6174652d3633354246463f7374796c653d666f722d7468652d6261646765266c6f676f3d737472697065266c6f676f436f6c6f723d7768697465)](https://buy.stripe.com/aFadR8gIaflgfQV6T4fw400) |

## ğŸ“„ License

No license file is present in the current repository snapshot.

Assumption note: until a `LICENSE` file is added, reuse/distribution terms are undefined.

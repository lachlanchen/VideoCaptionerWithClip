[English](../README.md) Â· [Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©](README.ar.md) Â· [EspaÃ±ol](README.es.md) Â· [FranÃ§ais](README.fr.md) Â· [æ—¥æœ¬èª](README.ja.md) Â· [í•œêµ­ì–´](README.ko.md) Â· [Tiáº¿ng Viá»‡t](README.vi.md) Â· [ä¸­æ–‡ (ç®€ä½“)](README.zh-Hans.md) Â· [ä¸­æ–‡ï¼ˆç¹é«”ï¼‰](README.zh-Hant.md) Â· [Deutsch](README.de.md) Â· [Ğ ÑƒÑÑĞºĞ¸Ğ¹](README.ru.md)



[![LazyingArt banner](https://github.com/lachlanchen/lachlanchen/raw/main/figs/banner.png)](https://github.com/lachlanchen/lachlanchen/blob/main/figs/banner.png)

# Clip-GPT-Captioning

![Python](https://img.shields.io/badge/Python-3.10%2B-blue)
![PyTorch](https://img.shields.io/badge/PyTorch-2.x-red)
![Transformers](https://img.shields.io/badge/HuggingFace-Transformers-yellow)
![Status](https://img.shields.io/badge/README-Expanded-success)
![Repo Layout](https://img.shields.io/badge/Layout-Root%20Scripts-informational)
![Legacy Scripts](https://img.shields.io/badge/Legacy%20Scripts-Present-orange)
![i18n](https://img.shields.io/badge/i18n-Enabled-brightgreen)
![Maintained Path](https://img.shields.io/badge/Video-v2c.py-2ea44f)
![Contributions](https://img.shields.io/badge/Contributions-Welcome-2ea44f?style=flat-square)
![Issues](https://img.shields.io/github/issues-raw/lachlanchen/VideoCaptionerWithClip?style=flat-square)
![Last Commit](https://img.shields.io/github/last-commit/lachlanchen/VideoCaptionerWithClip?style=flat-square)

---

## ğŸ§­ ë¹ ë¥¸ ë„¤ë¹„ê²Œì´ì…˜

| ì„¹ì…˜ | ìš©ë„ |
|---|---|
| Snapshot | ì €ì¥ì†Œ ë²”ìœ„ì™€ í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ êµ¬ì„±ì„ í™•ì¸ |
| Overview | ëª©í‘œì™€ ê¸°ëŠ¥ì„ í™•ì¸ |
| Usage | ì •í™•í•œ CLI/API ì‚¬ìš© íë¦„ì„ ë”°ë¦„ |
| Troubleshooting | ì¼ë°˜ì ì¸ ëŸ°íƒ€ì„ ì´ìŠˆë¥¼ ë¹ ë¥´ê²Œ í•´ê²° |
| Roadmap | ì •ë¦¬/ê°œì„  ì˜ˆì • í•­ëª©ì„ í™•ì¸ |

---

OpenAI CLIPì˜ ì‹œê° ì„ë² ë”©ê³¼ GPT ê³„ì—´ ì–¸ì–´ ëª¨ë¸ì„ ê²°í•©í•´ ì´ë¯¸ì§€ ë° ë¹„ë””ì˜¤ì˜ ìì—°ì–´ ìº¡ì…˜ì„ ìƒì„±í•˜ëŠ” Python ë„êµ¬ ëª¨ìŒì…ë‹ˆë‹¤.

## ğŸ§­ Snapshot

| ë²”ì£¼ | ë‚´ìš© |
|---|---|
| ì‘ì—… ë²”ìœ„ | ì´ë¯¸ì§€ ë° ë¹„ë””ì˜¤ ìº¡ì…”ë‹ |
| í•µì‹¬ ì‚°ì¶œë¬¼ | SRT ìë§‰, JSON ìë§‰, ìº¡ì…˜ì´ ë¶™ì€ ì´ë¯¸ì§€ |
| ì£¼ìš” ìŠ¤í¬ë¦½íŠ¸ | `i2c.py`, `v2c.py`, `image2caption.py` |
| ë ˆê±°ì‹œ ê²½ë¡œ | `video2caption.py` ë° ë²„ì „ë³„ ë™ìƒ íŒŒì¼ë“¤ (ê¸°ë¡ìš©ìœ¼ë¡œ ìœ ì§€) |
| ë°ì´í„°ì…‹ íë¦„ | `data/raw/results.csv` + `data/raw/flickr30k_images/` |

## âœ¨ ê°œìš”

ì´ ì €ì¥ì†ŒëŠ” ë‹¤ìŒ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤:

- ì´ë¯¸ì§€ ìº¡ì…˜ ìƒì„± ë° ë¹„ë””ì˜¤ ìë§‰ ìƒì„±ì„ ìœ„í•œ ì¶”ë¡  ìŠ¤í¬ë¦½íŠ¸.
- CLIP ì‹œê° ì„ë² ë”©ì„ GPT-2 í† í° ì„ë² ë”©ìœ¼ë¡œ ë§¤í•‘í•˜ëŠ” í•™ìŠµ íŒŒì´í”„ë¼ì¸.
- Flickr30k ìŠ¤íƒ€ì¼ ë°ì´í„°ì…‹ ìƒì„±ì„ ìœ„í•œ ìœ í‹¸ë¦¬í‹°.
- í•„ìš”í•œ ëª¨ë¸ ê°€ì¤‘ì¹˜ê°€ ì—†ì„ ë•Œ ì§€ì›ë˜ëŠ” í¬ê¸°ì˜ ì²´í¬í¬ì¸íŠ¸ë¥¼ ìë™ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œ.
- `i18n/` í•˜ìœ„ì˜ ë‹¤êµ­ì–´ README ë²„ì „(ìœ„ì˜ ì–¸ì–´ ë°” ì°¸ì¡°).

í˜„ì¬ êµ¬í˜„ì—ëŠ” ì‹ ê·œ ìŠ¤í¬ë¦½íŠ¸ì™€ ë ˆê±°ì‹œ ìŠ¤í¬ë¦½íŠ¸ê°€ ëª¨ë‘ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì¼ë¶€ ë ˆê±°ì‹œ íŒŒì¼ì€ ì°¸ì¡°ìš©ìœ¼ë¡œ ë³´ì¡´ë˜ì–´ ìˆìœ¼ë©° ì•„ë˜ì— ì •ë¦¬ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

## ğŸš€ íŠ¹ì§•

- `image2caption.py`ë¥¼ í†µí•œ ë‹¨ì¼ ì´ë¯¸ì§€ ìº¡ì…˜ ìƒì„±.
- `v2c.py` ë˜ëŠ” `video2caption.py`ë¥¼ í†µí•œ ë¹„ë””ì˜¤ ìº¡ì…˜ ìƒì„±(ê· ë“± í”„ë ˆì„ ìƒ˜í”Œë§).
- ì‹¤í–‰ ì˜µì…˜ ì»¤ìŠ¤í„°ë§ˆì´ì¦ˆ:
  - í”„ë ˆì„ ìˆ˜.
  - ëª¨ë¸ í¬ê¸°.
  - ìƒ˜í”Œë§ ì˜¨ë„.
  - ì²´í¬í¬ì¸íŠ¸ ì´ë¦„.
- ë©€í‹°í”„ë¡œì„¸ì‹±/ìŠ¤ë ˆë“œ ê¸°ë°˜ ìº¡ì…˜ ì²˜ë¦¬ë¡œ ë¹„ë””ì˜¤ ì¶”ë¡  ì†ë„ í–¥ìƒ.
- ì¶œë ¥ ì‚°ì¶œë¬¼:
  - SRT ìë§‰ íŒŒì¼ (`.srt`).
  - `v2c.py`ì—ì„œ ìƒì„±ë˜ëŠ” JSON ì „ì‚¬ë³¸ (`.json`).
- CLIP+GPT2 ë§¤í•‘ ì‹¤í—˜ì„ ìœ„í•œ í•™ìŠµ ë° í‰ê°€ ì§„ì…ì .

### í•œëˆˆì— ë³´ê¸°

| ì˜ì—­ | ì£¼ìš” ìŠ¤í¬ë¦½íŠ¸ | ë¹„ê³  |
|---|---|---|
| ì´ë¯¸ì§€ ìº¡ì…”ë‹ | `image2caption.py`, `i2c.py`, `predict.py` | CLI + ì¬ì‚¬ìš© ê°€ëŠ¥í•œ í´ë˜ìŠ¤ |
| ë¹„ë””ì˜¤ ìº¡ì…”ë‹ | `v2c.py` | ìœ ì§€ë³´ìˆ˜ ê¶Œì¥ ê²½ë¡œ |
| ë ˆê±°ì‹œ ë¹„ë””ì˜¤ í”Œë¡œìš° | `video2caption.py`, `video2caption_v1.1.py` | ì¥ë¹„ íŠ¹í™” ê°€ì •ê°’ í¬í•¨ |
| ë°ì´í„°ì…‹ êµ¬ì¶• | `dataset_generation.py` | `data/processed/dataset.pkl` ìƒì„± |
| í•™ìŠµ/í‰ê°€ | `training.py`, `evaluate.py` | CLIP+GPT2 ë§¤í•‘ ì‚¬ìš© |

## ğŸ§± ì•„í‚¤í…ì²˜ (ê°œìš”)

`model/model.py`ì˜ í•µì‹¬ ëª¨ë¸ì€ ì„¸ ë¶€ë¶„ìœ¼ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤:

1. `ImageEncoder`: CLIP ì´ë¯¸ì§€ ì„ë² ë”© ì¶”ì¶œ.
2. `Mapping`: CLIP ì„ë² ë”©ì„ GPT ì ‘ë‘ì‚¬ ì„ë² ë”© ì‹œí€€ìŠ¤ë¡œ íˆ¬ì˜.
3. `TextDecoder`: GPT-2 ì–¸ì–´ ëª¨ë¸ í—¤ë“œê°€ ìê¸°íšŒê·€ ë°©ì‹ìœ¼ë¡œ ìº¡ì…˜ í† í° ìƒì„±.

í•™ìŠµ(`Net.train_forward`)ì€ ë¯¸ë¦¬ ê³„ì‚°ëœ CLIP ì´ë¯¸ì§€ ì„ë² ë”© + í† í°í™”ëœ ìº¡ì…˜ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
ì¶”ë¡ (`Net.forward`)ì€ PIL ì´ë¯¸ì§€ë¥¼ ë°›ì•„ EOS ë˜ëŠ” `max_len`ì— ë„ë‹¬í•  ë•Œê¹Œì§€ í† í°ì„ ë””ì½”ë”©í•©ë‹ˆë‹¤.

### ë°ì´í„° íë¦„

1. ë°ì´í„°ì…‹ ì¤€ë¹„: `dataset_generation.py`ê°€ `data/raw/results.csv`ì™€ `data/raw/flickr30k_images/`ì˜ ì´ë¯¸ì§€ë¥¼ ì½ì–´ `data/processed/dataset.pkl`ì„ ì‘ì„±.
2. í•™ìŠµ: `training.py`ê°€ í”¼í´ íŠœí”Œ `(image_name, image_embedding, caption)`ì„ ë¡œë“œí•˜ê³  ë§¤í¼/ë””ì½”ë” ê³„ì¸µì„ í•™ìŠµ.
3. í‰ê°€: `evaluate.py`ê°€ ë³´ë¥˜ëœ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ì— ëŒ€í•œ ì˜ˆì¸¡ ìº¡ì…˜ì„ ì¶œë ¥.
4. ì¶”ë¡  ì‹¤í–‰:
   - ì´ë¯¸ì§€: `image2caption.py` / `predict.py` / `i2c.py`.
   - ë¹„ë””ì˜¤: `v2c.py`(ê¶Œì¥), `video2caption.py`(ë ˆê±°ì‹œ).

## ğŸ—‚ï¸ í”„ë¡œì íŠ¸ êµ¬ì¡°

```text
VideoCaptionerWithClip/
â”œâ”€â”€ README.md
â”œâ”€â”€ image2caption.py               # Single-image caption CLI
â”œâ”€â”€ predict.py                     # Alternate single-image caption CLI
â”œâ”€â”€ i2c.py                         # Reusable ImageCaptioner class + CLI
â”œâ”€â”€ v2c.py                         # Video -> SRT + JSON (threaded frame captioning)
â”œâ”€â”€ video2caption.py               # Alternate video -> SRT implementation (legacy constraints)
â”œâ”€â”€ video2caption_v1.1.py          # Older variant
â”œâ”€â”€ video2caption_v1.0_not_work.py # Explicitly marked non-working legacy file
â”œâ”€â”€ training.py                    # Model training entrypoint
â”œâ”€â”€ evaluate.py                    # Test-split evaluation and rendered outputs
â”œâ”€â”€ dataset_generation.py          # Builds data/processed/dataset.pkl
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ dataset.py                 # Dataset + DataLoader helpers
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ model.py                   # CLIP encoder + mapping + GPT2 decoder
â”‚   â””â”€â”€ trainer.py                 # Training/validation/test utility class
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                  # ConfigS / ConfigL defaults
â”‚   â”œâ”€â”€ downloads.py               # Google Drive checkpoint downloader
â”‚   â””â”€â”€ lr_warmup.py               # LR warmup schedule
â”œâ”€â”€ i18n/                          # Multilingual README variants
â””â”€â”€ .auto-readme-work/             # Auto-README pipeline artifacts
```

## ğŸ“‹ ì„ í–‰ ì¡°ê±´

- Python `3.10+` ê¶Œì¥.
- CUDA ì§€ì› GPUëŠ” ì„ íƒì´ì§€ë§Œ, í•™ìŠµê³¼ ëŒ€í˜• ëª¨ë¸ ì¶”ë¡ ì—ì„œëŠ” ê°•ë ¥ ê¶Œì¥ë©ë‹ˆë‹¤.
- í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ì—ì„œëŠ” `ffmpeg`ê°€ ì§ì ‘ ìš”êµ¬ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤(OpenCVê°€ í”„ë ˆì„ ì¶”ì¶œì— ì‚¬ìš©ë¨).
- Hugging Face / Google Driveì—ì„œ ëª¨ë¸/ì²´í¬í¬ì¸íŠ¸ë¥¼ ì²˜ìŒ ë‚´ë ¤ë°›ì„ ë•Œ ì¸í„°ë„· ì—°ê²°ì´ í•„ìš”í•©ë‹ˆë‹¤.

í˜„ì¬ `requirements.txt` ë˜ëŠ” `pyproject.toml` ê°™ì€ ì ê¸ˆ íŒŒì¼ì€ ì—†ìœ¼ë¯€ë¡œ ì˜ì¡´ì„±ì€ ì„í¬íŠ¸ í•­ëª©ì„ ê¸°ì¤€ìœ¼ë¡œ ì¶”ë¡ ë©ë‹ˆë‹¤.

## ğŸ› ï¸ ì„¤ì¹˜

### í˜„ì¬ ì €ì¥ì†Œ ë ˆì´ì•„ì›ƒ ê¸°ì¤€ ì •ì‹ ì„¤ì¹˜

```bash

git clone git@github.com:lachlanchen/VideoCaptionerWithClip.git
cd VideoCaptionerWithClip

python -m venv .venv
source .venv/bin/activate

pip install --upgrade pip
pip install torch torchvision torchaudio
pip install transformers pillow matplotlib numpy tqdm opencv-python pandas wandb gdown
```

### ì›ë³¸ README ì„¤ì¹˜ ìŠ¤ë‹ˆí«(ì›ë¬¸ ë³´ì¡´)

ì´ì „ READMEëŠ” ì¤‘ê°„ì— ë©ˆì¶˜ ìƒíƒœì˜€ìŠµë‹ˆë‹¤. ì›ë³¸ ì—­ì‚¬ì  ë‚´ìš©ì€ ë‹¤ìŒê³¼ ê°™ì´ ê·¸ëŒ€ë¡œ ë³´ì¡´ë©ë‹ˆë‹¤:

```bash
git clone git@github.com:lachlanchen/VideoCaptionerWithClip.git
cd VideoCaptionerWithClip/src
```

ì°¸ê³ : í˜„ì¬ ì €ì¥ì†Œ êµ¬ì¡°ì—ì„œëŠ” ìŠ¤í¬ë¦½íŠ¸ê°€ ë£¨íŠ¸ì— ìˆìœ¼ë©° `src/` í•˜ìœ„ê°€ ì•„ë‹™ë‹ˆë‹¤.

## â–¶ï¸ ë¹ ë¥¸ ì‹œì‘

| ëª©í‘œ | ëª…ë ¹ |
|---|---|
| ì´ë¯¸ì§€ ìº¡ì…˜ ìƒì„± | `python image2caption.py -I /path/to/image.jpg -S L -C model.pt` |
| ë¹„ë””ì˜¤ ìº¡ì…˜ ìƒì„± | `python v2c.py -V /path/to/video.mp4 -N 10` |
| ë°ì´í„°ì…‹ ë¹Œë“œ | `python dataset_generation.py` |

### ì´ë¯¸ì§€ ìº¡ì…”ë‹(ë¹ ë¥¸ ì‹¤í–‰)

```bash
python image2caption.py -I /path/to/image.jpg -S L -C model.pt
```

### ë¹„ë””ì˜¤ ìº¡ì…”ë‹(ê¶Œì¥ ê²½ë¡œ)

```bash
python v2c.py -V /path/to/video.mp4 -N 10
```

## ğŸ¯ ì‚¬ìš©ë²•

### 1. ì´ë¯¸ì§€ ìº¡ì…”ë‹ (`image2caption.py`)

```bash
python image2caption.py \
  -I /path/to/image.jpg \
  -S L \
  -C model.pt \
  -R ./data/result/prediction \
  -T 1.0
```

ì¸ì:

- `-I, --img-path`: ì…ë ¥ ì´ë¯¸ì§€ ê²½ë¡œ.
- `-S, --size`: ëª¨ë¸ í¬ê¸° (`S` ë˜ëŠ” `L`).
- `-C, --checkpoint-name`: `weights/{small|large}` ë‚´ ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ëª….
- `-R, --res-path`: ê²°ê³¼ ìº¡ì…˜ ì´ë¯¸ì§€ê°€ ì €ì¥ë  ë””ë ‰í„°ë¦¬.
- `-T, --temperature`: ìƒ˜í”Œë§ ì˜¨ë„.

### 2. ëŒ€ì²´ ì´ë¯¸ì§€ CLI (`predict.py`)

```bash
python predict.py \
  -I /path/to/image.jpg \
  -S L \
  -C model.pt \
  -R ./data/result/prediction \
  -T 1.0
```

`predict.py`ëŠ” `image2caption.py`ì™€ ê¸°ëŠ¥ì ìœ¼ë¡œ ìœ ì‚¬í•˜ì§€ë§Œ, ì¶œë ¥ í…ìŠ¤íŠ¸ í¬ë§·ì´ ì•½ê°„ ë‹¤ë¦…ë‹ˆë‹¤.

### 3. ì´ë¯¸ì§€ ìº¡ì…”ë‹ í´ë˜ìŠ¤ API (`i2c.py`)

```bash
python i2c.py -I /path/to/image.jpg -S L -C model.pt -R ./data/result/prediction -T 1.0
```

ë˜ëŠ” ì§ì ‘ ìŠ¤í¬ë¦½íŠ¸ì—ì„œ ì„í¬íŠ¸:

```python
from i2c import ImageCaptioner

captioner = ImageCaptioner(model_size="L", checkpoint_name="model.pt")
captioner.set_image_path("/path/to/image.jpg")
caption = captioner.generate_caption(save_image=True)
print(caption)
```

### 4. ë¹„ë””ì˜¤ ìë§‰ + JSON (`v2c.py`)

```bash
python v2c.py -V /path/to/video.mp4 -N 10
```

ì…ë ¥ ë¹„ë””ì˜¤ì™€ ë™ì¼ í´ë”ì— ì¶œë ¥:

- `<video_basename>_caption.srt`
- `<video_basename>_caption.json`
- `<video_basename>_captioning_frames/`

### 5. ëŒ€ì²´ ë¹„ë””ì˜¤ íŒŒì´í”„ë¼ì¸ (`video2caption.py`)

```bash
python video2caption.py -V /path/to/video.mp4 -N 10
```

ì¤‘ìš”: ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” í˜„ì¬ ì¥ë¹„ íŠ¹í™” í•˜ë“œì½”ë”© ê²½ë¡œë¥¼ í¬í•¨í•©ë‹ˆë‹¤.

- Python ê¸°ë³¸ ê²½ë¡œ: `/home/lachlan/miniconda3/envs/caption/bin/python`
- ìº¡ì…˜ ìŠ¤í¬ë¦½íŠ¸ ê²½ë¡œ: `/home/lachlan/Projects/image_captioning/clip-gpt-captioning/src/image2caption.py`

ì´ ê²½ë¡œë¥¼ ì˜ë„ì ìœ¼ë¡œ ìœ ì§€í•˜ì§€ ì•ŠëŠ” ì´ìƒ `v2c.py` ì‚¬ìš©ì„ ê¶Œì¥í•©ë‹ˆë‹¤.

### 6. ë ˆê±°ì‹œ ë³€í˜• (`video2caption_v1.1.py`)

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ê¸°ë¡ ë³´ì¡´ ëª©ì ìœ¼ë¡œë§Œ ë‚¨ê²¨ë‘¡ë‹ˆë‹¤. ì‹¤ì œ ì‚¬ìš©ì€ `v2c.py`ë¥¼ ìš°ì„ í•˜ì„¸ìš”.

### 7. ë°ì´í„°ì…‹ ìƒì„±

```bash
python dataset_generation.py
```

í•„ìˆ˜ ì…ë ¥:

- `data/raw/results.csv` (íŒŒì´í”„(`|`) êµ¬ë¶„ ìº¡ì…˜ í…Œì´ë¸”)
- `data/raw/flickr30k_images/` (CSVì—ì„œ ì°¸ì¡°í•˜ëŠ” ì´ë¯¸ì§€ íŒŒì¼ë“¤)

ì¶œë ¥:

- `data/processed/dataset.pkl`

### 8. í•™ìŠµ

```bash
python training.py -S L -C model.pt
```

í•™ìŠµì€ ê¸°ë³¸ì ìœ¼ë¡œ Weights & Biases(`wandb`) ë¡œê¹…ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

### 9. í‰ê°€

```bash
python evaluate.py \
  -I ./data/raw/flickr30k_images \
  -R ./data/result/eval \
  -S L \
  -C model.pt \
  -T 1.0
```

í‰ê°€ ì‹œ ì˜ˆì¸¡ ìº¡ì…˜ì´ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ì— ë Œë”ë§ë˜ì–´ ë‹¤ìŒ ìœ„ì¹˜ì— ì €ì¥ë©ë‹ˆë‹¤.

- `<res-path>/<checkpoint_name_without_ext>_<SIZE>/`

## âš™ï¸ ì„¤ì •

ëª¨ë¸ ì„¤ì •ì€ `utils/config.py`ì—ì„œ ì •ì˜ë©ë‹ˆë‹¤.

| Config | CLIP ë°±ë³¸ | GPT ëª¨ë¸ | ê°€ì¤‘ì¹˜ í´ë” |
|---|---|---|---|
| `ConfigS` | `openai/clip-vit-base-patch32` | `gpt2` | `weights/small` |
| `ConfigL` | `openai/clip-vit-large-patch14` | `gpt2-medium` | `weights/large` |

ì„¤ì • í´ë˜ìŠ¤ì˜ ì£¼ìš” ê¸°ë³¸ê°’:

| í•„ë“œ | `ConfigS` | `ConfigL` |
|---|---:|---:|
| `epochs` | 150 | 120 |
| `lr` | 3e-3 | 5e-3 |
| `batch_size_exp` | 6 | 5 |
| `ep_len` | 4 | 4 |
| `max_len` | 40 | 40 |

ì²´í¬í¬ì¸íŠ¸ ìë™ ë‹¤ìš´ë¡œë“œ IDëŠ” `utils/downloads.py`ì— ìˆìŠµë‹ˆë‹¤.

| í¬ê¸° | Google Drive ID |
|---|---|
| `L` | `1Gh32arzhW06C1ZJyzcJSSfdJDi3RgWoG` |
| `S` | `1pSQruQyg8KJq6VmzhMLFbT_VaHJMdlWF` |

## ğŸ“¦ ì¶œë ¥ íŒŒì¼

### ì´ë¯¸ì§€ ì¶”ë¡ 

- `--res-path` ìœ„ì¹˜ì— ìº¡ì…˜ í…ìŠ¤íŠ¸ê°€ ì˜¤ë²„ë ˆì´ëœ ì´ë¯¸ì§€ê°€ ì €ì¥ë©ë‹ˆë‹¤.
- íŒŒì¼ëª… ê·œì¹™: `<input_stem>-R<SIZE>.jpg`.

### ë¹„ë””ì˜¤ ì¶”ë¡  (`v2c.py`)

- SRT: `<video_stem>_caption.srt`
- JSON: `<video_stem>_caption.json`
- í”„ë ˆì„ ì´ë¯¸ì§€: `<video_stem>_captioning_frames/`

JSON ì˜ˆì‹œ:

```json
{
  "start": "00:00:03,200",
  "end": "00:00:03,700",
  "lang": "en",
  "text": "A dog running through a field."
}
```

## ğŸ§ª ì‚¬ìš© ì˜ˆì‹œ

### ë¹ ë¥¸ ì´ë¯¸ì§€ ìº¡ì…˜ ì˜ˆì‹œ

```bash
python image2caption.py -I ./examples/dog.jpg -S S -C model.pt
```

ì˜ˆìƒ ë™ì‘:

- `weights/small/model.pt`ê°€ ì—†ìœ¼ë©´ ìë™ ë‹¤ìš´ë¡œë“œë©ë‹ˆë‹¤.
- ìº¡ì…˜ì´ ë“¤ì–´ê°„ ì´ë¯¸ì§€ê°€ ê¸°ë³¸ì ìœ¼ë¡œ `./data/result/prediction`ì— ì €ì¥ë©ë‹ˆë‹¤.
- ìº¡ì…˜ í…ìŠ¤íŠ¸ê°€ stdoutìœ¼ë¡œ ì¶œë ¥ë©ë‹ˆë‹¤.

### ë¹ ë¥¸ ë¹„ë””ì˜¤ ìº¡ì…˜ ì˜ˆì‹œ

```bash
python v2c.py -V ./examples/demo.mp4 -N 8
```

ì˜ˆìƒ ë™ì‘:

- 8ê°œì˜ ê· ì¼ ìƒ˜í”Œë§ í”„ë ˆì„ì´ ìº¡ì…˜ë©ë‹ˆë‹¤.
- ì…ë ¥ ë¹„ë””ì˜¤ ì˜†ì— `.srt`ì™€ `.json` íŒŒì¼ì´ ìƒì„±ë©ë‹ˆë‹¤.

### ì—”ë“œíˆ¬ì—”ë“œ í•™ìŠµ/í‰ê°€ ìˆœì„œ

```bash
python dataset_generation.py
python training.py -S L -C model.pt
python evaluate.py -I ./data/raw/flickr30k_images -R ./data/result/eval -S L -C model.pt -T 1.0
```

## ğŸ§­ ê°œë°œ ë…¸íŠ¸

- `v2c.py`, `video2caption.py`, `video2caption_v1.*` ê°„ì— ë ˆê±°ì‹œ ì¤‘ì²©ì´ ì¡´ì¬í•©ë‹ˆë‹¤.
- `video2caption_v1.0_not_work.py`ëŠ” ì˜ë„ì ìœ¼ë¡œ ë™ì‘í•˜ì§€ ì•ŠëŠ” ë ˆê±°ì‹œ ì½”ë“œë¡œ ë³´ì¡´ë©ë‹ˆë‹¤.
- `training.py`ëŠ” í˜„ì¬ `config = ConfigL() if args.size.upper() else ConfigS()`ë¥¼ ì‚¬ìš©í•´, ë¹ˆ ê°’ì´ ì•„ë‹Œ `--size`ê°€ ë“¤ì–´ê°€ë©´ í•­ìƒ `ConfigL`ë¡œ í•´ì„ë©ë‹ˆë‹¤.
- `model/trainer.py`ëŠ” `test_step`ì—ì„œ `self.dataset`ì„ ì‚¬ìš©í•˜ì§€ë§Œ, ì´ˆê¸°í™”ëŠ” `self.test_dataset`ì— í• ë‹¹ë˜ì–´ ìˆì–´ í•™ìŠµ ì‹¤í–‰ ì‹œ ìƒ˜í”Œë§ì´ ê¹¨ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- `video2caption_v1.1.py`ëŠ” `self.config.transform`ì„ ì°¸ì¡°í•˜ì§€ë§Œ, `ConfigS`/`ConfigL`ì—ëŠ” `transform`ì´ ì •ì˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.
- ì´ ì €ì¥ì†Œ ìŠ¤ëƒ…ìƒ·ì—ëŠ” í˜„ì¬ CI/í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸ê°€ ì •ì˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.
- i18n ì°¸ê³ : ìƒë‹¨ì˜ ì–¸ì–´ ë§í¬ê°€ ì¡´ì¬í•˜ë©° ë²ˆì—­ íŒŒì¼ì€ `i18n/`ì— ì¶”ê°€ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- í˜„ì¬ ìƒíƒœ: ì–¸ì–´ ë°”ì—ëŠ” `i18n/README.ru.md` ë§í¬ê°€ ìˆìœ¼ë‚˜, í˜„ì¬ ìŠ¤ëƒ…ìƒ·ì—ëŠ” í•´ë‹¹ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.

## ğŸ©º íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

- `AssertionError: Image does not exist`
  - `-I/--img-path`ê°€ ì‹¤ì œ íŒŒì¼ì„ ê°€ë¦¬í‚¤ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.
- `Dataset file not found. Downloading...`
  - `MiniFlickrDataset`ëŠ” `data/processed/dataset.pkl`ì´ ì—†ì„ ë•Œ í•´ë‹¹ ë©”ì‹œì§€ë¥¼ ë„ì›ë‹ˆë‹¤. ë¨¼ì € `python dataset_generation.py` ì‹¤í–‰.
- `Path to the test image folder does not exist`
  - `evaluate.py -I`ê°€ ê¸°ì¡´ í´ë”ë¥¼ ê°€ë¦¬í‚¤ëŠ”ì§€ í™•ì¸.
- ì´ˆê¸° ì‹¤í–‰ì´ ëŠë¦¬ê±°ë‚˜ ì‹¤íŒ¨
  - ì²« ì‹¤í–‰ì—ì„œ Hugging Face ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•˜ê³  Google Drive ì²´í¬í¬ì¸íŠ¸ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- `video2caption.py`ê°€ ë¹ˆ ìº¡ì…˜ì„ ë°˜í™˜
  - í•˜ë“œì½”ë”©ëœ ìŠ¤í¬ë¦½íŠ¸ ê²½ë¡œì™€ Python ì‹¤í–‰ ê²½ë¡œë¥¼ í™•ì¸í•˜ê±°ë‚˜ `v2c.py`ë¡œ ì „í™˜.
- `wandb`ê°€ í•™ìŠµ ì¤‘ ë¡œê·¸ì¸ ìš”ì²­
  - `wandb login` ì‹¤í–‰ ë˜ëŠ” í•„ìš” ì‹œ `training.py`ì—ì„œ ë¡œê¹… ë¹„í™œì„±í™”.

## ğŸ›£ï¸ ë¡œë“œë§µ

- ì¬í˜„ ê°€ëŠ¥í•œ ì„¤ì¹˜ë¥¼ ìœ„í•œ ì˜ì¡´ì„± ì ê¸ˆ íŒŒì¼(`requirements.txt` ë˜ëŠ” `pyproject.toml`) ì¶”ê°€.
- ì¤‘ë³µ ë¹„ë””ì˜¤ íŒŒì´í”„ë¼ì¸ì„ í•˜ë‚˜ì˜ ìœ ì§€ë³´ìˆ˜ ê²½ë¡œë¡œ í†µí•©.
- ë ˆê±°ì‹œ ìŠ¤í¬ë¦½íŠ¸ì˜ í•˜ë“œì½”ë”© ê²½ë¡œ ì œê±°.
- `training.py`ì™€ `model/trainer.py`ì˜ ì•Œë ¤ì§„ í•™ìŠµ/í‰ê°€ ì—£ì§€ ì¼€ì´ìŠ¤ ë²„ê·¸ ìˆ˜ì •.
- ìë™í™” í…ŒìŠ¤íŠ¸ ë° CI ì¶”ê°€.
- ì–¸ì–´ ë°”ì—ì„œ ì°¸ì¡°ë˜ëŠ” ë²ˆì—­ README íŒŒì¼ì„ `i18n/`ì— ì‹¤ì œë¡œ ì±„ì›€.

## ğŸ¤ ê¸°ì—¬

ê¸°ì—¬ë¥¼ í™˜ì˜í•©ë‹ˆë‹¤. ê¶Œì¥ ì‘ì—… íë¦„:

```bash
# 1) Fork and clone
git clone git@github.com:<your-user>/VideoCaptionerWithClip.git
cd VideoCaptionerWithClip

# 2) Create a feature branch
git checkout -b feat/your-change

# 3) Make changes and commit
git add .
git commit -m "feat: describe your change"

# 4) Push and open a PR
git push origin feat/your-change
```

ëª¨ë¸ ë™ì‘ì„ ë³€ê²½í•œë‹¤ë©´ ë‹¤ìŒì„ í¬í•¨í•˜ì„¸ìš”:

- ì¬í˜„ ê°€ëŠ¥í•œ ì‹¤í–‰ ëª…ë ¹.
- ë³€ê²½ ì „í›„ ìƒ˜í”Œ ì¶œë ¥.
- ì²´í¬í¬ì¸íŠ¸ ë˜ëŠ” ë°ì´í„°ì…‹ ê°€ì •ì— ëŒ€í•œ ë…¸íŠ¸.

---

## ğŸ“„ ë¼ì´ì„ ìŠ¤

í˜„ì¬ ì €ì¥ì†Œ ìŠ¤ëƒ…ìƒ·ì—ëŠ” ë¼ì´ì„ ìŠ¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.

ì°¸ê³ : `LICENSE` íŒŒì¼ì´ ì¶”ê°€ë  ë•Œê¹Œì§€ ì¬ì‚¬ìš© ë° ë°°í¬ ì¡°ê±´ì´ ì •í•´ì ¸ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.


## â¤ï¸ Support

| Donate | PayPal | Stripe |
| --- | --- | --- |
| [![Donate](https://camo.githubusercontent.com/24a4914f0b42c6f435f9e101621f1e52535b02c225764b2f6cc99416926004b7/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f446f6e6174652d4c617a79696e674172742d3045413545393f7374796c653d666f722d7468652d6261646765266c6f676f3d6b6f2d6669266c6f676f436f6c6f723d7768697465)](https://chat.lazying.art/donate) | [![PayPal](https://camo.githubusercontent.com/d0f57e8b016517a4b06961b24d0ca87d62fdba16e18bbdb6aba28e978dc0ea21/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f50617950616c2d526f6e677a686f754368656e2d3030343537433f7374796c653d666f722d7468652d6261646765266c6f676f3d70617970616c266c6f676f436f6c6f723d7768697465)](https://paypal.me/RongzhouChen) | [![Stripe](https://camo.githubusercontent.com/1152dfe04b6943afe3a8d2953676749603fb9f95e24088c92c97a01a897b4942/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f5374726970652d446f6e6174652d3633354246463f7374796c653d666f722d7468652d6261646765266c6f676f3d737472697065266c6f676f436f6c6f723d7768697465)](https://buy.stripe.com/aFadR8gIaflgfQV6T4fw400) |

[English](../README.md) Â· [Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©](README.ar.md) Â· [EspaÃ±ol](README.es.md) Â· [FranÃ§ais](README.fr.md) Â· [æ—¥æœ¬èª](README.ja.md) Â· [í•œêµ­ì–´](README.ko.md) Â· [Tiáº¿ng Viá»‡t](README.vi.md) Â· [ä¸­æ–‡ (ç®€ä½“)](README.zh-Hans.md) Â· [ä¸­æ–‡ï¼ˆç¹é«”ï¼‰](README.zh-Hant.md) Â· [Deutsch](README.de.md) Â· [Ğ ÑƒÑÑĞºĞ¸Ğ¹](README.ru.md)



[![LazyingArt banner](https://github.com/lachlanchen/lachlanchen/raw/main/figs/banner.png)](https://github.com/lachlanchen/lachlanchen/blob/main/figs/banner.png)


# Clip-GPT-Captioning

![Python](https://img.shields.io/badge/Python-3.10%2B-blue)
![PyTorch](https://img.shields.io/badge/PyTorch-2.x-red)
![Transformers](https://img.shields.io/badge/HuggingFace-Transformers-yellow)
![Status](https://img.shields.io/badge/README-Expanded-success)
![Repo Layout](https://img.shields.io/badge/Layout-Root%20Scripts-informational)
![Legacy Scripts](https://img.shields.io/badge/Legacy%20Scripts-Present-orange)
![i18n](https://img.shields.io/badge/i18n-Enabled-brightgreen)
![Maintained Path](https://img.shields.io/badge/Video-v2c.py-2ea44f)
![Contributions](https://img.shields.io/badge/Contributions-Welcome-2ea44f?style=flat-square)
![Issues](https://img.shields.io/github/issues-raw/lachlanchen/VideoCaptionerWithClip?style=flat-square)
![Last Commit](https://img.shields.io/github/last-commit/lachlanchen/VideoCaptionerWithClip?style=flat-square)

---

## ğŸ§­ å¿«é€Ÿå¯¼èˆª

| Section | What to use it for |
|---|---|
| Snapshot | æŸ¥çœ‹ä»“åº“èŒƒå›´å’Œå½“å‰è„šæœ¬æ¸…å• |
| Overview | é˜…è¯»ç›®æ ‡å’ŒåŠŸèƒ½ |
| Usage | æŒ‰ç…§ç²¾ç¡®çš„ CLI/API æµç¨‹ä½¿ç”¨ |
| Troubleshooting | å¿«é€Ÿæ’æŸ¥å¸¸è§è¿è¡Œé—®é¢˜ |
| Roadmap | è·Ÿè¿›å·²çŸ¥æ¸…ç†å’Œæ”¹è¿›ç›®æ ‡ |

---

ä¸€ä¸ªå°† OpenAI CLIP å›¾åƒç‰¹å¾ä¸ GPT é£æ ¼è¯­è¨€æ¨¡å‹ç»“åˆï¼Œç”¨äºç”Ÿæˆå›¾åƒä¸è§†é¢‘è‡ªç„¶è¯­è¨€å­—å¹•çš„ Python å·¥å…·åŒ…ã€‚

## ğŸ§­ å¿«ç…§

| Dimension | Details |
|---|---|
| ä»»åŠ¡è¦†ç›–èŒƒå›´ | å›¾åƒä¸è§†é¢‘å­—å¹•ç”Ÿæˆ |
| æ ¸å¿ƒäº§ç‰© | SRT å­—å¹•ã€JSON è½¬å½•æ–‡æœ¬ã€å¸¦å­—å¹•çš„å›¾åƒ |
| ä¸»è¦è„šæœ¬ | `i2c.py`ã€`v2c.py`ã€`image2caption.py` |
| æ—§è·¯å¾„ | `video2caption.py` åŠå…¶ç‰ˆæœ¬åˆ†æ”¯ï¼ˆä¿ç•™ç”¨äºå†å²å‚è€ƒï¼‰ |
| æ•°æ®é›†æµç¨‹ | `data/raw/results.csv` + `data/raw/flickr30k_images/` |

## âœ¨ æ¦‚è§ˆ

è¯¥ä»“åº“æä¾›ä»¥ä¸‹å†…å®¹ï¼š

- å›¾åƒå­—å¹•ä¸è§†é¢‘å­—å¹•ç”Ÿæˆæ¨ç†è„šæœ¬ã€‚
- å­¦ä¹  CLIP å›¾åƒåµŒå…¥åˆ° GPT-2 token åµŒå…¥æ˜ å°„çš„è®­ç»ƒæµæ°´çº¿ã€‚
- ç”¨äº Flickr30k é£æ ¼æ•°æ®çš„ æ•°æ®é›†ç”Ÿæˆå·¥å…·ã€‚
- åœ¨æƒé‡ç¼ºå¤±æ—¶è‡ªåŠ¨ä¸‹è½½æ‰€æ”¯æŒæ¨¡å‹å°ºå¯¸çš„æ£€æŸ¥ç‚¹ã€‚
- `i18n/` ä¸‹çš„å¤šè¯­è¨€ README ç‰ˆæœ¬ï¼ˆè§ä¸Šæ–¹è¯­è¨€æ ï¼‰ã€‚

å½“å‰å®ç°åŒæ—¶ä¿ç•™äº†è¾ƒæ–°è„šæœ¬ä¸å†å²é—ç•™è„šæœ¬ã€‚éƒ¨åˆ†æ—§æ–‡ä»¶ä»…ä¿ç•™ç”¨äºå‚è€ƒï¼Œåœ¨ä¸‹æ–¹æœ‰è¯´æ˜ã€‚

## ğŸš€ åŠŸèƒ½

- é€šè¿‡ `image2caption.py` æ”¯æŒå•å¼ å›¾åƒå­—å¹•ç”Ÿæˆã€‚
- é€šè¿‡ `v2c.py` æˆ– `video2caption.py` æ”¯æŒè§†é¢‘å­—å¹•ï¼ˆå‡åŒ€æŠ½å¸§ï¼‰ã€‚
- å¯è‡ªå®šä¹‰è¿è¡Œå‚æ•°ï¼š
  - å¸§æ•°
  - æ¨¡å‹å¤§å°
  - é‡‡æ ·æ¸©åº¦
  - æ£€æŸ¥ç‚¹åç§°
- å¤šè¿›ç¨‹ / å¤šçº¿ç¨‹åŠ é€Ÿè§†é¢‘æ¨ç†ã€‚
- è¾“å‡ºæ–‡ä»¶ï¼š
  - SRT å­—å¹•æ–‡ä»¶ï¼ˆ`.srt`ï¼‰
  - `v2c.py` è¾“å‡ºçš„ JSON è½¬å½•æ–‡æœ¬ï¼ˆ`.json`ï¼‰
- CLIP+GPT2 æ˜ å°„å®éªŒçš„è®­ç»ƒä¸è¯„ä¼°å…¥å£ã€‚

### ä¸€è§ˆ

| Area | Primary script(s) | Notes |
|---|---|---|
| å›¾åƒå­—å¹• | `image2caption.py`ã€`i2c.py`ã€`predict.py` | CLI ä¸å¯å¤ç”¨ç±» |
| è§†é¢‘å­—å¹• | `v2c.py` | æ¨èçš„ä¸»ç»´æŠ¤è·¯å¾„ |
| æ—§ç‰ˆè§†é¢‘æµç¨‹ | `video2caption.py`ã€`video2caption_v1.1.py` | åŒ…å«æœºå™¨ç›¸å…³çš„ç¡¬ç¼–ç å‡è®¾ |
| æ•°æ®é›†æ„å»º | `dataset_generation.py` | ç”Ÿæˆ `data/processed/dataset.pkl` |
| è®­ç»ƒ / è¯„ä¼° | `training.py`ã€`evaluate.py` | ä½¿ç”¨ CLIP+GPT2 æ˜ å°„ |

## ğŸ§± æ¶æ„ï¼ˆé«˜å±‚ï¼‰

`model/model.py` ä¸­çš„æ ¸å¿ƒæ¨¡å‹åŒ…å«ä¸‰éƒ¨åˆ†ï¼š

1. `ImageEncoder`ï¼šæå– CLIP å›¾åƒåµŒå…¥ã€‚
2. `Mapping`ï¼šå°† CLIP åµŒå…¥æ˜ å°„åˆ° GPT å‰ç¼€åµŒå…¥åºåˆ—ã€‚
3. `TextDecoder`ï¼šGPT-2 è§£ç å¤´ï¼ŒæŒ‰è‡ªå›å½’æ–¹å¼ç”Ÿæˆå­—å¹• tokenã€‚

è®­ç»ƒé˜¶æ®µï¼ˆ`Net.train_forward`ï¼‰ä½¿ç”¨é¢„è®¡ç®—çš„ CLIP å›¾åƒåµŒå…¥ä¸åˆ†è¯åçš„å­—å¹•ã€‚
æ¨ç†é˜¶æ®µï¼ˆ`Net.forward`ï¼‰ä½¿ç”¨ PIL å›¾åƒå¹¶æŒç»­è§£ç  tokenï¼Œç›´åˆ° EOS æˆ– `max_len`ã€‚

### æ•°æ®æµ

1. å‡†å¤‡æ•°æ®é›†ï¼š`dataset_generation.py` è¯»å– `data/raw/results.csv` ä¸ `data/raw/flickr30k_images/` ä¸­çš„å›¾åƒï¼Œå†™å…¥ `data/processed/dataset.pkl`ã€‚
2. è®­ç»ƒï¼š`training.py` è½½å…¥ pickled å…ƒç»„ `(image_name, image_embedding, caption)` å¹¶è®­ç»ƒæ˜ å°„å±‚ä¸è§£ç å±‚ã€‚
3. è¯„ä¼°ï¼š`evaluate.py` åœ¨ç•™å‡ºæµ‹è¯•å›¾åƒä¸Šæ¸²æŸ“ç”Ÿæˆå­—å¹•ã€‚
4. æä¾›æ¨ç†å…¥å£ï¼š
   - å›¾åƒï¼š`image2caption.py` / `predict.py` / `i2c.py`
   - è§†é¢‘ï¼š`v2c.py`ï¼ˆæ¨èï¼‰ã€`video2caption.py`ï¼ˆå†å²ç‰ˆæœ¬ï¼‰

## ğŸ—‚ï¸ é¡¹ç›®ç»“æ„

```text
VideoCaptionerWithClip/
â”œâ”€â”€ README.md
â”œâ”€â”€ image2caption.py               # å•å¼ å›¾åƒå­—å¹• CLI
â”œâ”€â”€ predict.py                     # æ›¿ä»£çš„å•å¼ å›¾åƒå­—å¹• CLI
â”œâ”€â”€ i2c.py                         # å¯å¤ç”¨çš„ ImageCaptioner ç±» + CLI
â”œâ”€â”€ v2c.py                         # è§†é¢‘ -> SRT + JSONï¼ˆå¤šçº¿ç¨‹é€å¸§å­—å¹•ï¼‰
â”œâ”€â”€ video2caption.py               # æ›¿ä»£çš„è§†é¢‘ -> SRT å®ç°ï¼ˆé—ç•™é™åˆ¶ï¼‰
â”œâ”€â”€ video2caption_v1.1.py          # æ›´æ—©ç‰ˆæœ¬
â”œâ”€â”€ video2caption_v1.0_not_work.py # æ˜ç¡®æ ‡æ³¨ä¸ºä¸å†å¯ç”¨çš„é—ç•™æ–‡ä»¶
â”œâ”€â”€ training.py                    # æ¨¡å‹è®­ç»ƒå…¥å£
â”œâ”€â”€ evaluate.py                    # æµ‹è¯•é›†è¯„ä¼°ä¸ç»“æœæ¸²æŸ“
â”œâ”€â”€ dataset_generation.py          # æ„å»º data/processed/dataset.pkl
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ dataset.py                 # Dataset + DataLoader è¾…åŠ©
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ model.py                   # CLIP ç¼–ç å™¨ + æ˜ å°„ + GPT2 è§£ç å™¨
â”‚   â””â”€â”€ trainer.py                 # è®­ç»ƒ/éªŒè¯/æµ‹è¯•è¾…åŠ©ç±»
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                  # ConfigS / ConfigL é»˜è®¤é…ç½®
â”‚   â”œâ”€â”€ downloads.py               # Google Drive æ£€æŸ¥ç‚¹ä¸‹è½½å·¥å…·
â”‚   â””â”€â”€ lr_warmup.py               # å­¦ä¹ ç‡çƒ­èº«è°ƒåº¦
â”œâ”€â”€ i18n/                          # å¤šè¯­è¨€ README ç‰ˆæœ¬
â””â”€â”€ .auto-readme-work/             # è‡ªåŠ¨ README æµæ°´çº¿äº§ç‰©
```

## ğŸ“‹ å‰ç½®æ¡ä»¶

- æ¨è Python `3.10+`ã€‚
- è®­ç»ƒä¸å¤§æ¨¡å‹æ¨ç†å»ºè®®å…·å¤‡ CUDA GPUï¼›éå¿…é¡»ã€‚
- å½“å‰è„šæœ¬ä¸ç›´æ¥ä¾èµ– `ffmpeg`ï¼ˆå¸§æŠ½å–ä½¿ç”¨ OpenCVï¼‰ã€‚
- é¦–æ¬¡ä» Hugging Face / Google Drive ä¸‹è½½æ¨¡å‹æˆ–æ£€æŸ¥ç‚¹æ—¶éœ€è¦è”ç½‘ã€‚

å½“å‰ä»“åº“æš‚æœªæä¾›é”æ–‡ä»¶ï¼ˆç¼ºå°‘ `requirements.txt` / `pyproject.toml`ï¼‰ï¼Œå› æ­¤ä¾èµ–ä»¥ import å¼•ç”¨ä¸ºå‡†ã€‚

## ğŸ› ï¸ å®‰è£…

### æŒ‰å½“å‰ä»“åº“å¸ƒå±€è¿›è¡Œæ ‡å‡†å®‰è£…

```bash

git clone git@github.com:lachlanchen/VideoCaptionerWithClip.git
cd VideoCaptionerWithClip

python -m venv .venv
source .venv/bin/activate

pip install --upgrade pip
pip install torch torchvision torchaudio
pip install transformers pillow matplotlib numpy tqdm opencv-python pandas wandb gdown
```

### ä¿ç•™å†å² README çš„å®‰è£…ç‰‡æ®µ

åŸå§‹ README åœ¨ä¸­é—´å¤„ä¸­æ–­ã€‚ä¸ºä¿ç•™å†å²å†…å®¹ï¼Œä»¥ä¸‹å‘½ä»¤æŒ‰åŸæ ·ä¿ç•™ï¼š

```bash
git clone git@github.com:lachlanchen/VideoCaptionerWithClip.git
cd VideoCaptionerWithClip/src
```

æ³¨æ„ï¼šå½“å‰ä»“åº“å¿«ç…§å°†è„šæœ¬æ”¾åœ¨ä»“åº“æ ¹ç›®å½•ï¼Œè€Œé `src/`ã€‚

## â–¶ï¸ å¿«é€Ÿå¼€å§‹

| Goal | Command |
|---|---|
| ç”Ÿæˆå›¾åƒå­—å¹• | `python image2caption.py -I /path/to/image.jpg -S L -C model.pt` |
| ç”Ÿæˆè§†é¢‘å­—å¹• | `python v2c.py -V /path/to/video.mp4 -N 10` |
| æ„å»ºæ•°æ®é›† | `python dataset_generation.py` |

### å›¾åƒå­—å¹•ï¼ˆå¿«é€Ÿè¿è¡Œï¼‰

```bash
python image2caption.py -I /path/to/image.jpg -S L -C model.pt
```

### è§†é¢‘å­—å¹•ï¼ˆæ¨èè·¯å¾„ï¼‰

```bash
python v2c.py -V /path/to/video.mp4 -N 10
```

## ğŸ¯ ç”¨æ³•

### 1. å›¾åƒå­—å¹•ï¼ˆ`image2caption.py`ï¼‰

```bash
python image2caption.py \
  -I /path/to/image.jpg \
  -S L \
  -C model.pt \
  -R ./data/result/prediction \
  -T 1.0
```

å‚æ•°è¯´æ˜ï¼š

- `-I, --img-path`ï¼šè¾“å…¥å›¾ç‰‡è·¯å¾„ã€‚
- `-S, --size`ï¼šæ¨¡å‹å¤§å°ï¼ˆ`S` æˆ– `L`ï¼‰ã€‚
- `-C, --checkpoint-name`ï¼š`weights/{small|large}` ä¸‹çš„æ£€æŸ¥ç‚¹æ–‡ä»¶åã€‚
- `-R, --res-path`ï¼šæ¸²æŸ“åå¸¦å­—å¹•å›¾åƒçš„è¾“å‡ºç›®å½•ã€‚
- `-T, --temperature`ï¼šé‡‡æ ·æ¸©åº¦ã€‚

### 2. æ›¿ä»£å›¾åƒ CLIï¼ˆ`predict.py`ï¼‰

```bash
python predict.py \
  -I /path/to/image.jpg \
  -S L \
  -C model.pt \
  -R ./data/result/prediction \
  -T 1.0
```

`predict.py` ä¸ `image2caption.py` åŠŸèƒ½ä¸€è‡´ï¼›ä»…è¾“å‡ºæ–‡æœ¬æ ¼å¼ç•¥æœ‰å·®å¼‚ã€‚

### 3. å›¾åƒå­—å¹•ç±» APIï¼ˆ`i2c.py`ï¼‰

```bash
python i2c.py -I /path/to/image.jpg -S L -C model.pt -R ./data/result/prediction -T 1.0
```

æˆ–åœ¨ä½ è‡ªå·±çš„è„šæœ¬ä¸­å¯¼å…¥ï¼š

```python
from i2c import ImageCaptioner

captioner = ImageCaptioner(model_size="L", checkpoint_name="model.pt")
captioner.set_image_path("/path/to/image.jpg")
caption = captioner.generate_caption(save_image=True)
print(caption)
```

### 4. è§†é¢‘å­—å¹• + JSONï¼ˆ`v2c.py`ï¼‰

```bash
python v2c.py -V /path/to/video.mp4 -N 10
```

è¾“å‡ºæ–‡ä»¶ä½äºè¾“å…¥è§†é¢‘åŒç›®å½•ï¼š

- `<video_basename>_caption.srt`
- `<video_basename>_caption.json`
- `<video_basename>_captioning_frames/`

### 5. æ›¿ä»£è§†é¢‘æµç¨‹ï¼ˆ`video2caption.py`ï¼‰

```bash
python video2caption.py -V /path/to/video.mp4 -N 10
```

é‡è¦æç¤ºï¼šè¯¥è„šæœ¬ç›®å‰åŒ…å«æœºå™¨ç›¸å…³çš„ç¡¬ç¼–ç è·¯å¾„ï¼š

- Python é»˜è®¤è·¯å¾„ï¼š`/home/lachlan/miniconda3/envs/caption/bin/python`
- å­—å¹•è„šæœ¬è·¯å¾„ï¼š`/home/lachlan/Projects/image_captioning/clip-gpt-captioning/src/image2caption.py`

é™¤éä½ æœ‰æ„ç»´æŠ¤è¿™äº›è·¯å¾„ï¼Œå¦åˆ™è¯·ä½¿ç”¨ `v2c.py`ã€‚

### 6. å†å²ç‰ˆæœ¬ï¼ˆ`video2caption_v1.1.py`ï¼‰

è¯¥è„šæœ¬ä»…ä¿ç•™ç”¨äºå†å²å‚è€ƒã€‚æ—¥å¸¸ä½¿ç”¨è¯·ä¼˜å…ˆé€‰ç”¨ `v2c.py`ã€‚

### 7. æ•°æ®é›†ç”Ÿæˆ

```bash
python dataset_generation.py
```

æœŸæœ›è¾“å…¥ï¼š

- `data/raw/results.csv`ï¼ˆåˆ¶è¡¨ç¬¦åˆ†éš”çš„å­—å¹•è¡¨ï¼‰
- `data/raw/flickr30k_images/`ï¼ˆCSV ä¸­å¼•ç”¨çš„å›¾åƒæ–‡ä»¶ï¼‰

è¾“å‡ºï¼š

- `data/processed/dataset.pkl`

### 8. è®­ç»ƒ

```bash
python training.py -S L -C model.pt
```

è®­ç»ƒé»˜è®¤å¯ç”¨ Weights & Biasesï¼ˆ`wandb`ï¼‰æ—¥å¿—ã€‚

### 9. è¯„ä¼°

```bash
python evaluate.py \
  -I ./data/raw/flickr30k_images \
  -R ./data/result/eval \
  -S L \
  -C model.pt \
  -T 1.0
```

è¯„ä¼°ä¼šå°†é¢„æµ‹å­—å¹•æ¸²æŸ“åˆ°æµ‹è¯•å›¾åƒä¸Šï¼Œå¹¶ä¿å­˜åœ¨ï¼š

- `<res-path>/<checkpoint_name_without_ext>_<SIZE>/`

## âš™ï¸ é…ç½®

æ¨¡å‹é…ç½®å®šä¹‰åœ¨ `utils/config.py`ï¼š

| Config | CLIP backbone | GPT model | Weights dir |
|---|---|---|---|
| `ConfigS` | `openai/clip-vit-base-patch32` | `gpt2` | `weights/small` |
| `ConfigL` | `openai/clip-vit-large-patch14` | `gpt2-medium` | `weights/large` |

é…ç½®ç±»å…³é”®é»˜è®¤å€¼ï¼š

| Field | `ConfigS` | `ConfigL` |
|---|---:|---:|
| `epochs` | 150 | 120 |
| `lr` | 3e-3 | 5e-3 |
| `batch_size_exp` | 6 | 5 |
| `ep_len` | 4 | 4 |
| `max_len` | 40 | 40 |

æ£€æŸ¥ç‚¹è‡ªåŠ¨ä¸‹è½½ ID åœ¨ `utils/downloads.py` ä¸­ï¼š

| Size | Google Drive ID |
|---|---|
| `L` | `1Gh32arzhW06C1ZJyzcJSSfdJDi3RgWoG` |
| `S` | `1pSQruQyg8KJq6VmzhMLFbT_VaHJMdlWF` |

## ğŸ“¦ è¾“å‡ºæ–‡ä»¶

### å›¾åƒæ¨ç†

- åœ¨ `--res-path` ä¸‹ä¿å­˜å¸¦æœ‰å åŠ /ç”Ÿæˆæ ‡é¢˜çš„å›¾åƒã€‚
- æ–‡ä»¶åæ ¼å¼ï¼š`<input_stem>-R<SIZE>.jpg`ã€‚

### è§†é¢‘æ¨ç†ï¼ˆ`v2c.py`ï¼‰

- SRTï¼š`<video_stem>_caption.srt`
- JSONï¼š`<video_stem>_caption.json`
- å¸§å›¾åƒï¼š`<video_stem>_captioning_frames/`

ç¤ºä¾‹ JSON å…ƒç´ ï¼š

```json
{
  "start": "00:00:03,200",
  "end": "00:00:03,700",
  "lang": "en",
  "text": "A dog running through a field."
}
```

## ğŸ§ª ç¤ºä¾‹

### å¿«é€Ÿå›¾åƒå­—å¹•ç¤ºä¾‹

```bash
python image2caption.py -I ./examples/dog.jpg -S S -C model.pt
```

é¢„æœŸè¡¨ç°ï¼š

- è‹¥ `weights/small/model.pt` ç¼ºå¤±ä¼šè‡ªåŠ¨ä¸‹è½½ã€‚
- é»˜è®¤ä¼šå°†å¸¦å­—å¹•å›¾åƒå†™å…¥ `./data/result/prediction`ã€‚
- å­—å¹•æ–‡æœ¬ä¼šæ‰“å°åˆ°æ ‡å‡†è¾“å‡ºã€‚

### å¿«é€Ÿè§†é¢‘å­—å¹•ç¤ºä¾‹

```bash
python v2c.py -V ./examples/demo.mp4 -N 8
```

é¢„æœŸè¡¨ç°ï¼š

- ä¼šå¯¹ 8 å¸§å‡åŒ€é‡‡æ ·å›¾åƒç”Ÿæˆå­—å¹•ã€‚
- åŒæ—¶åœ¨è¾“å…¥è§†é¢‘æ—è¾¹ç”Ÿæˆ `.srt` ä¸ `.json` æ–‡ä»¶ã€‚

### ç«¯åˆ°ç«¯è®­ç»ƒ/è¯„ä¼°æµç¨‹

```bash
python dataset_generation.py
python training.py -S L -C model.pt
python evaluate.py -I ./data/raw/flickr30k_images -R ./data/result/eval -S L -C model.pt -T 1.0
```

## ğŸ§­ å¼€å‘è¯´æ˜

- `v2c.py`ã€`video2caption.py` ä¸ `video2caption_v1.*` ä¹‹é—´å­˜åœ¨é—ç•™åŠŸèƒ½é‡å ã€‚
- `video2caption_v1.0_not_work.py` æ•…æ„ä¿ç•™ä¸ºä¸å¯ç”¨çš„å†å²é—ç•™ä»£ç ã€‚
- `training.py` å½“å‰ä½¿ç”¨ `config = ConfigL() if args.size.upper() else ConfigS()` é€‰æ‹©é…ç½®ï¼Œéç©º `--size` ä¼šå§‹ç»ˆè§£æåˆ° `ConfigL`ã€‚
- `model/trainer.py` åœ¨ `test_step` ä¸­ä½¿ç”¨ `self.dataset`ï¼Œä½†åˆå§‹åŒ–æ—¶èµ‹å€¼çš„æ˜¯ `self.test_dataset`ï¼›è¿™ä¼šåœ¨è®­ç»ƒè¿è¡Œæ—¶å¯¼è‡´é‡‡æ ·é—®é¢˜ï¼Œéœ€ä¿®æ­£åå†ä½¿ç”¨ã€‚
- `video2caption_v1.1.py` å¼•ç”¨äº† `self.config.transform`ï¼Œä½† `ConfigS`/`ConfigL` å¹¶æœªå®šä¹‰è¯¥å­—æ®µã€‚
- æœ¬ä»“åº“å½“å‰æœªå®šä¹‰ CI / æµ‹è¯•å¥—ä»¶ã€‚
- i18n è¯´æ˜ï¼šè¯­è¨€æ ä½äºæœ¬ README é¡¶éƒ¨ï¼Œç¿»è¯‘æ–‡ä»¶å¯åœ¨ `i18n/` ä¸‹æ–°å¢ã€‚
- å½“å‰çŠ¶æ€è¯´æ˜ï¼šè¯­è¨€æ å·²æŒ‡å‘ `i18n/README.ru.md`ï¼Œä½†è¯¥æ–‡ä»¶åœ¨æ­¤å¿«ç…§ä¸­ä¸å­˜åœ¨ã€‚

## ğŸ©º æ•…éšœæ’æŸ¥

- `AssertionError: Image does not exist`
  - ç¡®è®¤ `-I/--img-path` æŒ‡å‘æœ‰æ•ˆæ–‡ä»¶ã€‚
- `Dataset file not found. Downloading...`
  - `MiniFlickrDataset` åœ¨ `data/processed/dataset.pkl` ç¼ºå¤±æ—¶æŠ›å‡ºï¼›å…ˆè¿è¡Œ `python dataset_generation.py`ã€‚
- `Path to the test image folder does not exist`
  - ç¡®è®¤ `evaluate.py -I` æŒ‡å‘å­˜åœ¨çš„æ–‡ä»¶å¤¹ã€‚
- é¦–æ¬¡è¿è¡Œç¼“æ…¢æˆ–å¤±è´¥
  - é¦–æ¬¡è¿è¡Œä¼šä¸‹è½½ Hugging Face æ¨¡å‹ï¼Œå¹¶å¯èƒ½ä» Google Drive æ‹‰å–æ£€æŸ¥ç‚¹ã€‚
- `video2caption.py` è¿”å›ç©ºå­—å¹•
  - æ£€æŸ¥ç¡¬ç¼–ç è„šæœ¬è·¯å¾„ä¸ Python æ‰§è¡Œè·¯å¾„ï¼Œæˆ–åˆ‡æ¢åˆ° `v2c.py`ã€‚
- è®­ç»ƒä¸­ `wandb` è¦æ±‚ç™»å½•
  - è¿è¡Œ `wandb login`ï¼Œæˆ–å¦‚æœ‰éœ€è¦åœ¨ `training.py` ä¸­æ‰‹åŠ¨ç¦ç”¨æ—¥å¿—ã€‚

## ğŸ›£ï¸ è·¯çº¿å›¾

- å¢åŠ ä¾èµ–é”æ–‡ä»¶ï¼ˆ`requirements.txt` æˆ– `pyproject.toml`ï¼‰ä»¥ä¾¿å¤ç°å®‰è£…ã€‚
- å°†é‡å¤çš„è§†é¢‘æµæ°´çº¿æ•´åˆä¸ºä¸€ä¸ªä¸»ç»´æŠ¤å®ç°ã€‚
- ä»é—ç•™è„šæœ¬ä¸­ç§»é™¤ç¡¬ç¼–ç æœºå™¨è·¯å¾„ã€‚
- ä¿®å¤ `training.py` ä¸ `model/trainer.py` ä¸­å·²çŸ¥è®­ç»ƒ/è¯„ä¼°è¾¹ç•Œé—®é¢˜ã€‚
- å¢åŠ è‡ªåŠ¨åŒ–æµ‹è¯•ä¸ CIã€‚
- åœ¨è¯­è¨€æ åˆ—å‡ºçš„ç›®æ ‡æ–‡ä»¶ä¸‹è¡¥å…… `i18n/` çš„ README ç¿»è¯‘ã€‚

## ğŸ¤ è´¡çŒ®

æ¬¢è¿è´¡çŒ®ã€‚å»ºè®®æµç¨‹ï¼š

```bash
# 1) Fork å¹¶ clone
git clone git@github.com:<your-user>/VideoCaptionerWithClip.git
cd VideoCaptionerWithClip

# 2) åˆ›å»ºç‰¹æ€§åˆ†æ”¯
git checkout -b feat/your-change

# 3) ä¿®æ”¹å¹¶æäº¤
git add .
git commit -m "feat: describe your change"

# 4) æ¨é€å¹¶æ PR
git push origin feat/your-change
```

å¦‚æœä½ ä¿®æ”¹äº†æ¨¡å‹è¡Œä¸ºï¼Œè¯·ä¸€å¹¶è¡¥å……ï¼š

- å¯å¤ç°çš„å‘½ä»¤
- ä¿®æ”¹å‰/åçš„æ ·ä¾‹è¾“å‡º
- æ£€æŸ¥ç‚¹ä¸æ•°æ®é›†å‡è®¾è¯´æ˜

---

## ğŸ“„ è®¸å¯è¯

å½“å‰ä»“åº“å¿«ç…§ä¸­æ²¡æœ‰è®¸å¯è¯æ–‡ä»¶ã€‚

è¯´æ˜ï¼šåœ¨æ·»åŠ  `LICENSE` æ–‡ä»¶å‰ï¼Œé‡ç”¨/åˆ†å‘æ¡æ¬¾å°šæœªå®šä¹‰ã€‚


## â¤ï¸ Support

| Donate | PayPal | Stripe |
| --- | --- | --- |
| [![Donate](https://camo.githubusercontent.com/24a4914f0b42c6f435f9e101621f1e52535b02c225764b2f6cc99416926004b7/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f446f6e6174652d4c617a79696e674172742d3045413545393f7374796c653d666f722d7468652d6261646765266c6f676f3d6b6f2d6669266c6f676f436f6c6f723d7768697465)](https://chat.lazying.art/donate) | [![PayPal](https://camo.githubusercontent.com/d0f57e8b016517a4b06961b24d0ca87d62fdba16e18bbdb6aba28e978dc0ea21/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f50617950616c2d526f6e677a686f754368656e2d3030343537433f7374796c653d666f722d7468652d6261646765266c6f676f3d70617970616c266c6f676f436f6c6f723d7768697465)](https://paypal.me/RongzhouChen) | [![Stripe](https://camo.githubusercontent.com/1152dfe04b6943afe3a8d2953676749603fb9f95e24088c92c97a01a897b4942/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f5374726970652d446f6e6174652d3633354246463f7374796c653d666f722d7468652d6261646765266c6f676f3d737472697065266c6f676f436f6c6f723d7768697465)](https://buy.stripe.com/aFadR8gIaflgfQV6T4fw400) |

[English](../README.md) Â· [Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©](README.ar.md) Â· [EspaÃ±ol](README.es.md) Â· [FranÃ§ais](README.fr.md) Â· [æ—¥æœ¬èª](README.ja.md) Â· [í•œêµ­ì–´](README.ko.md) Â· [Tiáº¿ng Viá»‡t](README.vi.md) Â· [ä¸­æ–‡ (ç®€ä½“)](README.zh-Hans.md) Â· [ä¸­æ–‡ï¼ˆç¹é«”ï¼‰](README.zh-Hant.md) Â· [Deutsch](README.de.md) Â· [Ğ ÑƒÑÑĞºĞ¸Ğ¹](README.ru.md)


[![LazyingArt banner](https://github.com/lachlanchen/lachlanchen/raw/main/figs/banner.png)](https://github.com/lachlanchen/lachlanchen/blob/main/figs/banner.png)

# Clip-GPT-Captioning

![Python](https://img.shields.io/badge/Python-3.10%2B-blue)
![PyTorch](https://img.shields.io/badge/PyTorch-2.x-red)
![Transformers](https://img.shields.io/badge/HuggingFace-Transformers-yellow)
![Status](https://img.shields.io/badge/README-Expanded-success)
![Repo Layout](https://img.shields.io/badge/Layout-Root%20Scripts-informational)
![Legacy Scripts](https://img.shields.io/badge/Legacy%20Scripts-Present-orange)
![i18n](https://img.shields.io/badge/i18n-Enabled-brightgreen)
![Maintained Path](https://img.shields.io/badge/Video-v2c.py-2ea44f)

ä¸€ä¸ª Python å·¥å…·åŒ…ï¼Œé€šè¿‡ç»“åˆ OpenAI CLIP è§†è§‰ç‰¹å¾ä¸ GPT é£æ ¼çš„è¯­è¨€æ¨¡å‹ï¼Œä¸ºå›¾åƒå’Œè§†é¢‘ç”Ÿæˆè‡ªç„¶è¯­è¨€æ ‡é¢˜ã€‚

## ğŸ§­ Snapshot

| ç»´åº¦ | è¯¦ç»†ä¿¡æ¯ |
|---|---|
| ä»»åŠ¡èŒƒå›´ | å›¾åƒä¸è§†é¢‘å­—å¹•ç”Ÿæˆ |
| æ ¸å¿ƒè¾“å‡º | SRT å­—å¹•ã€JSON è½¬å½•ã€å¸¦å­—å¹•å›¾åƒ |
| ä¸»è¦è„šæœ¬ | `i2c.py`ã€`v2c.py`ã€`image2caption.py` |
| å†å²è·¯å¾„ | `video2caption.py` åŠå…¶ç‰ˆæœ¬ï¼ˆä¿ç•™ç”¨äºå†å²å‚è€ƒï¼‰ |
| æ•°æ®é›†æµç¨‹ | `data/raw/results.csv` + `data/raw/flickr30k_images/` |

## âœ¨ æ¦‚è§ˆ

è¯¥ä»“åº“æä¾›ï¼š

- å›¾åƒæè¿°ä¸è§†é¢‘å­—å¹•ç”Ÿæˆæ¨ç†è„šæœ¬ã€‚
- è®­ç»ƒæµæ°´çº¿ï¼šå­¦ä¹  CLIP è§†è§‰åµŒå…¥åˆ° GPT-2 token åµŒå…¥çš„æ˜ å°„ã€‚
- ç”¨äº Flickr30k é£æ ¼æ•°æ®é›†çš„ç”Ÿæˆå·¥å…·ã€‚
- å½“ç¼ºå°‘æƒé‡æ—¶è‡ªåŠ¨ä¸‹è½½æ”¯æŒçš„æ¨¡å‹å°ºå¯¸ checkpointã€‚
- `i18n/` ä¸‹çš„å¤šè¯­è¨€ README ç‰ˆæœ¬ï¼ˆè§ä¸Šæ–¹è¯­è¨€æ ï¼‰ã€‚

å½“å‰å®ç°åŒ…å«è¾ƒæ–°è„šæœ¬ä¸å†å²é—ç•™è„šæœ¬ã€‚éƒ¨åˆ†é—ç•™æ–‡ä»¶ä¿ç•™ç”¨äºå‚è€ƒï¼Œå¹¶åœ¨ä¸‹æ–‡è¯´æ˜ã€‚

## ğŸš€ ç‰¹æ€§

- é€šè¿‡ `image2caption.py` å®ç°å•å¼ å›¾åƒæè¿°ã€‚
- é€šè¿‡ `v2c.py` æˆ– `video2caption.py` å®ç°è§†é¢‘æè¿°ï¼ˆå‡åŒ€é‡‡æ ·å¸§ï¼‰ã€‚
- å¯è‡ªå®šä¹‰è¿è¡Œé€‰é¡¹ï¼š
  - å¸§æ•°
  - æ¨¡å‹å°ºå¯¸
  - é‡‡æ ·æ¸©åº¦
  - Checkpoint åç§°
- å¤šè¿›ç¨‹/å¤šçº¿ç¨‹æ¨ç†ä»¥åŠ é€Ÿè§†é¢‘å­—å¹•ç”Ÿæˆã€‚
- è¾“å‡ºäº§ç‰©ï¼š
  - SRT å­—å¹•æ–‡ä»¶ï¼ˆ`.srt`ï¼‰
  - `v2c.py` çš„ JSON è½¬å½•æ–‡ä»¶ï¼ˆ`.json`ï¼‰
- CLIP+GPT2 æ˜ å°„å®éªŒçš„è®­ç»ƒä¸è¯„ä¼°å…¥å£ã€‚

### ä¸€è§ˆ

| æ¨¡å— | ä¸»è¦è„šæœ¬ | è¯´æ˜ |
|---|---|---|
| å›¾åƒæè¿° | `image2caption.py`, `i2c.py`, `predict.py` | CLI + å¯å¤ç”¨ç±» |
| è§†é¢‘æè¿° | `v2c.py` | æ¨èçš„ç»´æŠ¤è·¯å¾„ |
| é—ç•™è§†é¢‘æµç¨‹ | `video2caption.py`, `video2caption_v1.1.py` | åŒ…å«ç‰¹å®šæœºå™¨å‡è®¾ |
| æ•°æ®é›†æ„å»º | `dataset_generation.py` | ç”Ÿæˆ `data/processed/dataset.pkl` |
| è®­ç»ƒ / è¯„ä¼° | `training.py`, `evaluate.py` | ä½¿ç”¨ CLIP+GPT2 æ˜ å°„ |

## ğŸ§± æ¶æ„ï¼ˆé«˜å±‚ï¼‰

`model/model.py` ä¸­çš„æ ¸å¿ƒæ¨¡å‹ç”±ä¸‰éƒ¨åˆ†ç»„æˆï¼š

1. `ImageEncoder`ï¼šæå– CLIP å›¾åƒåµŒå…¥ã€‚
2. `Mapping`ï¼šå°† CLIP åµŒå…¥æŠ•å½±ä¸º GPT å‰ç¼€åµŒå…¥åºåˆ—ã€‚
3. `TextDecoder`ï¼šGPT-2 è¯­è¨€æ¨¡å‹å¤´ï¼Œè‡ªå›å½’ç”Ÿæˆæ ‡é¢˜ tokenã€‚

è®­ç»ƒï¼ˆ`Net.train_forward`ï¼‰ä½¿ç”¨é¢„è®¡ç®—çš„ CLIP å›¾åƒåµŒå…¥ä¸åˆ†è¯åçš„ captionsã€‚
æ¨ç†ï¼ˆ`Net.forward`ï¼‰ä½¿ç”¨ PIL å›¾åƒå¹¶æŒç»­è§£ç  tokenï¼Œç›´åˆ° EOS æˆ– `max_len`ã€‚

### æ•°æ®æµ

1. å‡†å¤‡æ•°æ®é›†ï¼š`dataset_generation.py` è¯»å– `data/raw/results.csv` ä¸ `data/raw/flickr30k_images/`ï¼Œå†™å…¥ `data/processed/dataset.pkl`ã€‚
2. è®­ç»ƒï¼š`training.py` åŠ è½½ pickle å…ƒç»„ `(image_name, image_embedding, caption)` å¹¶è®­ç»ƒæ˜ å°„/è§£ç å±‚ã€‚
3. è¯„ä¼°ï¼š`evaluate.py` åœ¨ç•™å‡ºçš„æµ‹è¯•å›¾åƒä¸Šæ¸²æŸ“ç”Ÿæˆçš„æè¿°ã€‚
4. æä¾›æ¨ç†ï¼š
   - å›¾åƒï¼š`image2caption.py` / `predict.py` / `i2c.py`
   - è§†é¢‘ï¼š`v2c.py`ï¼ˆæ¨èï¼‰ã€`video2caption.py`ï¼ˆé—ç•™ï¼‰

## ğŸ—‚ï¸ é¡¹ç›®ç»“æ„

```text
VideoCaptionerWithClip/
â”œâ”€â”€ README.md
â”œâ”€â”€ image2caption.py               # Single-image caption CLI
â”œâ”€â”€ predict.py                     # Alternate single-image caption CLI
â”œâ”€â”€ i2c.py                         # Reusable ImageCaptioner class + CLI
â”œâ”€â”€ v2c.py                         # Video -> SRT + JSON (threaded frame captioning)
â”œâ”€â”€ video2caption.py               # Alternate video -> SRT implementation (legacy constraints)
â”œâ”€â”€ video2caption_v1.1.py          # Older variant
â”œâ”€â”€ video2caption_v1.0_not_work.py # Explicitly marked non-working legacy file
â”œâ”€â”€ training.py                    # Model training entrypoint
â”œâ”€â”€ evaluate.py                    # Test-split evaluation and rendered outputs
â”œâ”€â”€ dataset_generation.py          # Builds data/processed/dataset.pkl
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ dataset.py                 # Dataset + DataLoader helpers
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ model.py                   # CLIP encoder + mapping + GPT2 decoder
â”‚   â””â”€â”€ trainer.py                 # Training/validation/test utility class
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                  # ConfigS / ConfigL defaults
â”‚   â”œâ”€â”€ downloads.py               # Google Drive checkpoint downloader
â”‚   â””â”€â”€ lr_warmup.py               # LR warmup schedule
â”œâ”€â”€ i18n/                          # Multilingual README variants
â””â”€â”€ .auto-readme-work/             # Auto-README pipeline artifacts
```

## ğŸ“‹ å‰ç½®æ¡ä»¶

- æ¨è Python `3.10+`ã€‚
- å…·å¤‡ CUDA çš„ GPU éå¿…éœ€ï¼Œä½†å¼ºçƒˆå»ºè®®ç”¨äºè®­ç»ƒå’Œå¤§æ¨¡å‹æ¨ç†ã€‚
- ç›®å‰è„šæœ¬æœªç›´æ¥ä¾èµ– `ffmpeg`ï¼ˆä½¿ç”¨ OpenCV è¿›è¡ŒæŠ½å¸§ï¼‰ã€‚
- é¦–æ¬¡ä» Hugging Face / Google Drive ä¸‹è½½æ¨¡å‹å’Œ checkpoint æ—¶éœ€è¦è”ç½‘ã€‚

å½“å‰ä»“åº“å¿«ç…§ä¸­æœªæä¾› lockfileï¼ˆç¼ºå°‘ `requirements.txt` / `pyproject.toml`ï¼‰ï¼Œå› æ­¤ä¾èµ–é¡¹éœ€ä»å¯¼å…¥ä¸­æ¨æ–­ã€‚

## ğŸ› ï¸ å®‰è£…

### åŸºäºå½“å‰ä»“åº“ç»“æ„çš„æ ‡å‡†å®‰è£…

```bash
git clone git@github.com:lachlanchen/VideoCaptionerWithClip.git
cd VideoCaptionerWithClip

python -m venv .venv
source .venv/bin/activate

pip install --upgrade pip
pip install torch torchvision torchaudio
pip install transformers pillow matplotlib numpy tqdm opencv-python pandas wandb gdown
```

### åŸ README çš„å®‰è£…ç‰‡æ®µï¼ˆä¿ç•™ï¼‰

åŸå§‹ README åœ¨ä¸­é€”ä¸­æ–­ã€‚æŒ‰å†å²åŸæ–‡ä¿ç•™å¦‚ä¸‹å‘½ä»¤ï¼Œä½œä¸ºæºçº§å‚è€ƒï¼š

```bash
git clone git@github.com:lachlanchen/VideoCaptionerWithClip.git
cd VideoCaptionerWithClip/src
```

æ³¨æ„ï¼šå½“å‰ä»“åº“å¿«ç…§ä¸­çš„è„šæœ¬ä½äºä»“åº“æ ¹ç›®å½•ï¼Œä¸åœ¨ `src/` ä¸‹ã€‚

## â–¶ï¸ å¿«é€Ÿå¼€å§‹

| ç›®æ ‡ | å‘½ä»¤ |
|---|---|
| ç”Ÿæˆå›¾åƒæ ‡é¢˜ | `python image2caption.py -I /path/to/image.jpg -S L -C model.pt` |
| ç”Ÿæˆè§†é¢‘æ ‡é¢˜ | `python v2c.py -V /path/to/video.mp4 -N 10` |
| æ„å»ºæ•°æ®é›† | `python dataset_generation.py` |

### å›¾åƒæè¿°ï¼ˆå¿«é€Ÿè¿è¡Œï¼‰

```bash
python image2caption.py -I /path/to/image.jpg -S L -C model.pt
```

### è§†é¢‘æè¿°ï¼ˆæ¨èè·¯å¾„ï¼‰

```bash
python v2c.py -V /path/to/video.mp4 -N 10
```

## ğŸ¯ ç”¨æ³•

### 1. å›¾åƒæè¿°ï¼ˆ`image2caption.py`ï¼‰

```bash
python image2caption.py \
  -I /path/to/image.jpg \
  -S L \
  -C model.pt \
  -R ./data/result/prediction \
  -T 1.0
```

å‚æ•°ï¼š

- `-I, --img-path`ï¼šè¾“å…¥å›¾åƒè·¯å¾„ã€‚
- `-S, --size`ï¼šæ¨¡å‹å°ºå¯¸ï¼ˆ`S` æˆ– `L`ï¼‰ã€‚
- `-C, --checkpoint-name`ï¼š`weights/{small|large}` ä¸­çš„ checkpoint æ–‡ä»¶åã€‚
- `-R, --res-path`ï¼šè¾“å‡ºæ¸²æŸ“åå›¾åƒçš„ç›®å½•ã€‚
- `-T, --temperature`ï¼šé‡‡æ ·æ¸©åº¦ã€‚

### 2. å¤‡ç”¨å›¾åƒ CLIï¼ˆ`predict.py`ï¼‰

```bash
python predict.py \
  -I /path/to/image.jpg \
  -S L \
  -C model.pt \
  -R ./data/result/prediction \
  -T 1.0
```

`predict.py` åœ¨åŠŸèƒ½ä¸Šä¸ `image2caption.py` ç›¸åŒï¼Œè¾“å‡ºæ–‡æœ¬æ ¼å¼ç•¥æœ‰å·®å¼‚ã€‚

### 3. å›¾åƒæè¿°ç±» APIï¼ˆ`i2c.py`ï¼‰

```bash
python i2c.py -I /path/to/image.jpg -S L -C model.pt -R ./data/result/prediction -T 1.0
```

æˆ–åœ¨ä½ è‡ªå·±çš„è„šæœ¬ä¸­å¯¼å…¥ä½¿ç”¨ï¼š

```python
from i2c import ImageCaptioner

captioner = ImageCaptioner(model_size="L", checkpoint_name="model.pt")
captioner.set_image_path("/path/to/image.jpg")
caption = captioner.generate_caption(save_image=True)
print(caption)
```

### 4. è§†é¢‘è½¬å­—å¹• + JSONï¼ˆ`v2c.py`ï¼‰

```bash
python v2c.py -V /path/to/video.mp4 -N 10
```

è¾“å‡ºä½äºè¾“å…¥è§†é¢‘åŒçº§ç›®å½•ï¼š

- `<video_basename>_caption.srt`
- `<video_basename>_caption.json`
- `<video_basename>_captioning_frames/`

### 5. å¤‡ç”¨è§†é¢‘æµç¨‹ï¼ˆ`video2caption.py`ï¼‰

```bash
python video2caption.py -V /path/to/video.mp4 -N 10
```

æ³¨æ„ï¼šè¯¥è„šæœ¬å½“å‰åŒ…å«æœºå™¨ç‰¹å®šç¡¬ç¼–ç è·¯å¾„ï¼š

- Python é»˜è®¤è·¯å¾„ï¼š`/home/lachlan/miniconda3/envs/caption/bin/python`
- æè¿°è„šæœ¬è·¯å¾„ï¼š`/home/lachlan/Projects/image_captioning/clip-gpt-captioning/src/image2caption.py`

é™¤éä½ æœ‰æ„ç»´æŠ¤è¿™äº›è·¯å¾„ï¼Œå¦åˆ™è¯·ä¼˜å…ˆä½¿ç”¨ `v2c.py`ã€‚

### 6. é—ç•™å˜ä½“ï¼ˆ`video2caption_v1.1.py`ï¼‰

è¯¥è„šæœ¬ä¿ç•™ä¸ºå†å²å‚è€ƒã€‚å®é™…ä½¿ç”¨è¯·ä¼˜å…ˆä½¿ç”¨ `v2c.py`ã€‚

### 7. æ•°æ®é›†ç”Ÿæˆ

```bash
python dataset_generation.py
```

æœŸæœ›è¾“å…¥ï¼š

- `data/raw/results.csv`ï¼ˆç”¨ç®¡é“åˆ†éš”çš„ captions è¡¨ï¼‰ã€‚
- `data/raw/flickr30k_images/`ï¼ˆCSV ä¸­å¼•ç”¨çš„å›¾åƒæ–‡ä»¶ï¼‰ã€‚

è¾“å‡ºï¼š

- `data/processed/dataset.pkl`

### 8. è®­ç»ƒ

```bash
python training.py -S L -C model.pt
```

è®­ç»ƒé»˜è®¤ä½¿ç”¨ Weights & Biasesï¼ˆ`wandb`ï¼‰æ—¥å¿—ã€‚

### 9. è¯„ä¼°

```bash
python evaluate.py \
  -I ./data/raw/flickr30k_images \
  -R ./data/result/eval \
  -S L \
  -C model.pt \
  -T 1.0
```

è¯„ä¼°ä¼šå°†é¢„æµ‹æè¿°æ¸²æŸ“åˆ°æµ‹è¯•å›¾åƒå¹¶ä¿å­˜åˆ°ï¼š

- `<res-path>/<checkpoint_name_without_ext>_<SIZE>/`

## âš™ï¸ é…ç½®

æ¨¡å‹é…ç½®å®šä¹‰åœ¨ `utils/config.py` ä¸­ï¼š

| é…ç½® | CLIP ä¸»å¹² | GPT æ¨¡å‹ | Weights ç›®å½• |
|---|---|---|---|
| `ConfigS` | `openai/clip-vit-base-patch32` | `gpt2` | `weights/small` |
| `ConfigL` | `openai/clip-vit-large-patch14` | `gpt2-medium` | `weights/large` |

é…ç½®ç±»å…³é”®é»˜è®¤å€¼ï¼š

| å­—æ®µ | `ConfigS` | `ConfigL` |
|---|---:|---:|
| `epochs` | 150 | 120 |
| `lr` | 3e-3 | 5e-3 |
| `batch_size_exp` | 6 | 5 |
| `ep_len` | 4 | 4 |
| `max_len` | 40 | 40 |

Checkpoint è‡ªåŠ¨ä¸‹è½½ ID å®šä¹‰äº `utils/downloads.py`ï¼š

| å°ºå¯¸ | Google Drive ID |
|---|---|
| `L` | `1Gh32arzhW06C1ZJyzcJSSfdJDi3RgWoG` |
| `S` | `1pSQruQyg8KJq6VmzhMLFbT_VaHJMdlWF` |

## ğŸ“¦ è¾“å‡ºæ–‡ä»¶

### å›¾åƒæ¨ç†

- åœ¨ `--res-path` ä¿å­˜å¸¦å åŠ /ç”Ÿæˆå­—å¹•çš„å›¾åƒã€‚
- æ–‡ä»¶åæ ¼å¼ï¼š`<input_stem>-R<SIZE>.jpg`ã€‚

### è§†é¢‘æ¨ç†ï¼ˆ`v2c.py`ï¼‰

- SRTï¼š`<video_stem>_caption.srt`
- JSONï¼š`<video_stem>_caption.json`
- å¸§å›¾åƒï¼š`<video_stem>_captioning_frames/`

JSON ç¤ºä¾‹ï¼š

```json
{
  "start": "00:00:03,200",
  "end": "00:00:03,700",
  "lang": "en",
  "text": "A dog running through a field."
}
```

## ğŸ§ª ç¤ºä¾‹

### å¿«é€Ÿå›¾åƒæè¿°ç¤ºä¾‹

```bash
python image2caption.py -I ./examples/dog.jpg -S S -C model.pt
```

é¢„æœŸè¡Œä¸ºï¼š

- è‹¥ç¼ºå°‘ `weights/small/model.pt`ï¼Œä¼šè‡ªåŠ¨ä¸‹è½½ã€‚
- é»˜è®¤å°†å¸¦æè¿°çš„å›¾åƒå†™å…¥ `./data/result/prediction`ã€‚
- æ ‡é¢˜æ–‡æœ¬å°†è¾“å‡ºåˆ° stdoutã€‚

### å¿«é€Ÿè§†é¢‘æè¿°ç¤ºä¾‹

```bash
python v2c.py -V ./examples/demo.mp4 -N 8
```

é¢„æœŸè¡Œä¸ºï¼š

- å°†å¯¹ 8 å¸§å‡åŒ€é‡‡æ ·å¸§ç”Ÿæˆæè¿°ã€‚
- åœ¨è¾“å…¥è§†é¢‘åŒç›®å½•ç”Ÿæˆ `.srt` ä¸ `.json` æ–‡ä»¶ã€‚

### ç«¯åˆ°ç«¯è®­ç»ƒ/è¯„ä¼°æµç¨‹

```bash
python dataset_generation.py
python training.py -S L -C model.pt
python evaluate.py -I ./data/raw/flickr30k_images -R ./data/result/eval -S L -C model.pt -T 1.0
```

## ğŸ§­ å¼€å‘è¯´æ˜

- `v2c.py`ã€`video2caption.py` ä¸ `video2caption_v1.*` ä¹‹é—´å­˜åœ¨é—ç•™é‡å ã€‚
- `video2caption_v1.0_not_work.py` è¢«æœ‰æ„ä¿ç•™ä¸ºä¸å¯ç”¨çš„é—ç•™ä»£ç ã€‚
- `training.py` å½“å‰é€šè¿‡ `config = ConfigL() if args.size.upper() else ConfigS()` é€‰æ‹© `ConfigL()`ï¼›å¯¹äºéç©º `--size`ï¼Œå§‹ç»ˆè§£æåˆ° `ConfigL`ã€‚
- `model/trainer.py` åœ¨ `test_step` ä¸­ä½¿ç”¨ `self.dataset`ï¼Œä½†åˆå§‹åŒ–å™¨èµ‹å€¼çš„æ˜¯ `self.test_dataset`ï¼›è‹¥æœªä¿®æ­£å¯èƒ½å¯¼è‡´è®­ç»ƒè¿è¡Œé‡‡æ ·å¼‚å¸¸ã€‚
- `video2caption_v1.1.py` å¼•ç”¨äº† `self.config.transform`ï¼Œä½† `ConfigS`/`ConfigL` æœªå®šä¹‰ `transform`ã€‚
- å½“å‰ä»“åº“å¿«ç…§å°šæœªå®šä¹‰ CI/test å¥—ä»¶ã€‚
- i18n è¯´æ˜ï¼šè¯­è¨€é“¾æ¥ä½äºæœ¬ README é¡¶éƒ¨ï¼Œç¿»è¯‘æ–‡ä»¶å¯è¡¥å……åˆ° `i18n/` ä¸‹ã€‚
- å½“å‰çŠ¶æ€è¯´æ˜ï¼šè¯­è¨€æ é“¾æ¥äº† `i18n/README.ru.md`ï¼Œä½†è¯¥æ–‡ä»¶åœ¨å½“å‰å¿«ç…§ä¸­ä¸å­˜åœ¨ã€‚

## ğŸ©º æ•…éšœæ’æŸ¥

- `AssertionError: Image does not exist`
  - ç¡®è®¤ `-I/--img-path` æŒ‡å‘æœ‰æ•ˆæ–‡ä»¶ã€‚
- `Dataset file not found. Downloading...`
  - å½“ç¼ºå°‘ `data/processed/dataset.pkl` æ—¶ï¼Œ`MiniFlickrDataset` ä¼šè§¦å‘ï¼›è¯·å…ˆè¿è¡Œ `python dataset_generation.py`ã€‚
- `Path to the test image folder does not exist`
  - ç¡®è®¤ `evaluate.py -I` æŒ‡å‘ä¸€ä¸ªçœŸå®å­˜åœ¨çš„æ–‡ä»¶å¤¹ã€‚
- é¦–æ¬¡è¿è¡Œè¾ƒæ…¢æˆ–å¤±è´¥
  - é¦–æ¬¡è¿è¡Œä¼šä¸‹è½½ Hugging Face æ¨¡å‹ï¼Œå¹¶å¯èƒ½ä» Google Drive ä¸‹è½½ checkpointã€‚
- `video2caption.py` è¿”å›ç©ºæè¿°
  - æ£€æŸ¥ç¡¬ç¼–ç è„šæœ¬è·¯å¾„å’Œ Python å¯æ‰§è¡Œè·¯å¾„ï¼Œæˆ–åˆ‡æ¢åˆ° `v2c.py`ã€‚
- è®­ç»ƒè¿‡ç¨‹ä¸­ `wandb` è¦æ±‚ç™»å½•
  - è¿è¡Œ `wandb login`ï¼Œæˆ–æŒ‰éœ€åœ¨ `training.py` ä¸­æ‰‹åŠ¨åœç”¨æ—¥å¿—ã€‚

## ğŸ›£ï¸ è·¯çº¿å›¾

- å¢åŠ ä¾èµ– lockfileï¼ˆ`requirements.txt` æˆ– `pyproject.toml`ï¼‰ä»¥å®ç°å¯å¤ç°å®‰è£…ã€‚
- å°†é‡å¤çš„è§†é¢‘æµæ°´çº¿åˆå¹¶ä¸ºå•ä¸€ç»´æŠ¤å®ç°ã€‚
- ç§»é™¤é—ç•™è„šæœ¬ä¸­çš„æœºå™¨ç¡¬ç¼–ç è·¯å¾„ã€‚
- ä¿®å¤ `training.py` å’Œ `model/trainer.py` ä¸­å·²çŸ¥çš„è®­ç»ƒ/è¯„ä¼°è¾¹ç•Œé—®é¢˜ã€‚
- å¢åŠ è‡ªåŠ¨åŒ–æµ‹è¯•ä¸ CIã€‚
- å®Œå–„ `i18n/` ä¸­è¯­è¨€æ ä¸­åˆ—å‡ºçš„ç¿»è¯‘ READMEã€‚

## ğŸ¤ è´¡çŒ®

æ¬¢è¿è´¡çŒ®ã€‚å»ºè®®å·¥ä½œæµå¦‚ä¸‹ï¼š

```bash
# 1) Fork å¹¶ clone
git clone git@github.com:<your-user>/VideoCaptionerWithClip.git
cd VideoCaptionerWithClip

# 2) åˆ›å»ºåˆ†æ”¯
git checkout -b feat/your-change

# 3) ä¿®æ”¹å¹¶æäº¤
git add .
git commit -m "feat: describe your change"

# 4) æ¨é€å¹¶æäº¤ PR
git push origin feat/your-change
```

å¦‚æœä½ ä¿®æ”¹æ¨¡å‹è¡Œä¸ºï¼Œè¯·åŒ…å«ï¼š

- å¯å¤ç°çš„å‘½ä»¤ã€‚
- ä¿®æ”¹å‰åçš„ç¤ºä¾‹è¾“å‡ºã€‚
- checkpoint æˆ–æ•°æ®é›†å‡è®¾è¯´æ˜ã€‚

## â¤ï¸ Support

| Donate | PayPal | Stripe |
|---|---|---|
| [![Donate](https://img.shields.io/badge/Donate-LazyingArt-0EA5E9?style=for-the-badge&logo=ko-fi&logoColor=white)](https://chat.lazying.art/donate) | [![PayPal](https://img.shields.io/badge/PayPal-RongzhouChen-00457C?style=for-the-badge&logo=paypal&logoColor=white)](https://paypal.me/RongzhouChen) | [![Stripe](https://img.shields.io/badge/Stripe-Donate-635BFF?style=for-the-badge&logo=stripe&logoColor=white)](https://buy.stripe.com/aFadR8gIaflgfQV6T4fw400) |

## ğŸ“„ è®¸å¯è¯

å½“å‰ä»“åº“å¿«ç…§ä¸­ä¸å­˜åœ¨è®¸å¯è¯æ–‡ä»¶ã€‚

å‡è®¾è¯´æ˜ï¼šåœ¨æ·»åŠ  `LICENSE` æ–‡ä»¶ä¹‹å‰ï¼Œå¤ç”¨ä¸åˆ†å‘æ¡æ¬¾å°šæœªå®šä¹‰ã€‚

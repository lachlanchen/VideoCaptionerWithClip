# Clipâ€‘GPTâ€‘Captioning

A Python toolkit for generating naturalâ€‘language captions on images and videos by combining OpenAIâ€™s CLIP for visual embeddings with a GPTâ€‘style language model.

---

## ðŸš€ Features

- **Singleâ€‘image captioning** via `image2caption.py`  
- **Video captioning** (uniform frame sampling) via `v2c.py` or `video2caption.py`  
- **Customizable**  
  - Number of frames, model size, temperature, checkpoint name  
- **Multiprocessing** for faster inference on videos  
- **Outputs**  
  - SRT subtitle files (`.srt`)  
  - JSON transcripts (`.json`)

---

## ðŸ”§ Installation

1. **Clone the repo**  
   ```bash
   git clone git@github.com:lachlanchen/VideoCaptionerWithClip.git
   cd VideoCaptionerWithClip/src

